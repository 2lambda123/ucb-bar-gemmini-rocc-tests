{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FFTRadNet/\")\n",
    "\n",
    "CUDA_fraktion = 0.25\n",
    "torch.cuda.set_per_process_memory_fraction(CUDA_fraktion, device=None)\n",
    "\n",
    "from model.FFTRadNet import FFTRadNet\n",
    "from dataset.dataset import RADIal\n",
    "from dataset.encoder import ra_encoder\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.util import DisplayHMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FFTRadNet(\n",
       "  (FPN): FPN_BackBone(\n",
       "    (pre_enc): MIMO_PreEncoder(\n",
       "      (conv): Conv2d(32, 192, kernel_size=(1, 12), stride=(1, 1), dilation=(1, 16), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (block1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(192, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(128, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 160, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(160, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(160, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(56, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(192, 224, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(224, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(224, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (RA_decoder): RangeAngle_Decoder(\n",
       "    (deconv4): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), output_padding=(1, 0))\n",
       "    (conv_block4): BasicBlock(\n",
       "      (conv1): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (deconv3): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), output_padding=(1, 0))\n",
       "    (conv_block3): BasicBlock(\n",
       "      (conv1): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (L3): Conv2d(192, 224, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (L2): Conv2d(160, 224, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (detection_header): Detection_Header(\n",
       "    (conv1): Conv2d(256, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(144, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv4): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (clshead): Conv2d(96, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (reghead): Conv2d(96, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (freespace): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = json.load(open('../../FFTRadNet_RA_192_56_epoch78_loss_172.8239_AP_0.9813/config.json'))\n",
    "\n",
    "model = FFTRadNet(blocks = config['model']['backbone_block'],\n",
    "                        mimo_layer  = config['model']['MIMO_output'],\n",
    "                        channels = config['model']['channels'], \n",
    "                        regression_layer = 2, \n",
    "                        detection_head = config['model']['DetectionHead'], \n",
    "                        segmentation_head = config['model']['SegmentationHead'])\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "dict = torch.load('../../FFTRadNet_RA_192_56_epoch78_loss_172.8239_AP_0.9813/FFTRadNet_RA_192_56_epoch78_loss_172.8239_AP_0.9813.pth')\n",
    "model.load_state_dict(dict['net_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFTRadNet(\n",
      "  (FPN): FPN_BackBone(\n",
      "    (pre_enc): MIMO_PreEncoder(\n",
      "      (conv): Conv2d(32, 192, kernel_size=(1, 12), stride=(1, 1), dilation=(1, 16), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (block1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(192, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (block2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(128, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 160, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (block3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(160, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(160, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (block4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(56, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(192, 224, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(224, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(224, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (RA_decoder): RangeAngle_Decoder(\n",
      "    (deconv4): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), output_padding=(1, 0))\n",
      "    (conv_block4): BasicBlock(\n",
      "      (conv1): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (deconv3): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), output_padding=(1, 0))\n",
      "    (conv_block3): BasicBlock(\n",
      "      (conv1): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (L3): Conv2d(192, 224, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (L2): Conv2d(160, 224, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (detection_header): Detection_Header(\n",
      "    (conv1): Conv2d(256, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(144, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv4): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (clshead): Conv2d(96, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (reghead): Conv2d(96, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (freespace): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): FPN_BackBone(\n",
       "    (pre_enc): MIMO_PreEncoder(\n",
       "      (conv): Conv2d(32, 192, kernel_size=(1, 12), stride=(1, 1), dilation=(1, 16), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (block1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(192, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(128, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 160, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(160, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(160, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(56, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(192, 224, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(224, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(224, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): RangeAngle_Decoder(\n",
       "    (deconv4): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), output_padding=(1, 0))\n",
       "    (conv_block4): BasicBlock(\n",
       "      (conv1): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (deconv3): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), output_padding=(1, 0))\n",
       "    (conv_block3): BasicBlock(\n",
       "      (conv1): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (L3): Conv2d(192, 224, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (L2): Conv2d(160, 224, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the real input data.\n",
    "# Copy all layers from the reference model except last two layers.\n",
    "# So the last layer of all_except_dh_sh is RangeAngle_Decoder:\n",
    "all_except_dh_sh = copy.deepcopy(model)\n",
    "all_except_dh_sh.load_state_dict(dict['net_state_dict'])\n",
    "all_except_dh_sh = torch.nn.Sequential(*list(all_except_dh_sh.children())[:-2])\n",
    "all_except_dh_sh.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input data for the Detection_Header:\n",
    "enc = ra_encoder(geometry = config['dataset']['geometry'], \n",
    "                        statistics = config['dataset']['statistics'],\n",
    "                        regression_layer = 2)\n",
    "\n",
    "dataset = RADIal(root_dir = config['dataset']['root_dir'],\n",
    "                        statistics= config['dataset']['statistics'],\n",
    "                        encoder=enc.encode)\n",
    "for data in dataset:\n",
    "    inputs = torch.tensor(data[0]).permute(2,0,1).to('cuda').float().unsqueeze(0)\n",
    "    y_pred = all_except_dh_sh(inputs)\n",
    "# save the all_except_dh_sh output / tensor to file:\n",
    "torch.save(y_pred, 'output_fftradnet_upto_rangeangle_model_014606.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 128, 224])\n",
      "tensor([[[[0.0000e+00, 2.5786e+00, 2.3156e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 8.7500e+00],\n",
      "          [8.3361e-01, 1.0027e+01, 8.7724e+00,  ..., 2.5602e-01,\n",
      "           0.0000e+00, 1.0810e+01],\n",
      "          [0.0000e+00, 4.6739e+00, 2.0324e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 1.0848e+01],\n",
      "          ...,\n",
      "          [0.0000e+00, 2.5932e+00, 1.5007e+00,  ..., 0.0000e+00,\n",
      "           2.8037e-01, 1.1255e+01],\n",
      "          [0.0000e+00, 3.8899e+00, 3.3342e+00,  ..., 7.7271e-01,\n",
      "           3.3343e+00, 1.2421e+01],\n",
      "          [0.0000e+00, 0.0000e+00, 3.3878e-03,  ..., 0.0000e+00,\n",
      "           2.8874e-01, 6.3513e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.0688e-01,\n",
      "           2.8319e+00, 7.2265e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.7522e-01,\n",
      "           2.6298e+00, 1.0072e+01],\n",
      "          [0.0000e+00, 0.0000e+00, 3.8028e-01,  ..., 0.0000e+00,\n",
      "           7.3995e-01, 9.1913e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 1.4414e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           4.6339e-01, 6.4133e+00],\n",
      "          [2.2298e+00, 5.9262e+00, 6.2331e+00,  ..., 3.8535e+00,\n",
      "           3.7944e+00, 8.1908e+00],\n",
      "          [3.0412e+00, 9.3745e+00, 1.2211e+01,  ..., 7.4621e+00,\n",
      "           7.2453e+00, 1.0326e+01]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 4.7955e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           2.2640e-02, 1.0073e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.5804e-02,\n",
      "           6.8150e-01, 6.7765e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[8.9879e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 1.0079e+00],\n",
      "          [1.1160e+00, 6.6353e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 5.0817e-01],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 5.0101e-01],\n",
      "          [6.8050e-01, 4.9644e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 1.6091e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[8.4392e+00, 1.1471e+01, 1.2019e+01,  ..., 8.9312e+00,\n",
      "           7.3110e+00, 4.1140e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 1.4773e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 2.0064e-01],\n",
      "          [1.4234e+00, 4.3043e-01, 2.1730e+00,  ..., 1.3668e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.1312e+00, 1.7009e+00, 2.5089e+00,  ..., 1.6497e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[9.8307e-01, 1.4448e+00, 2.2123e+00,  ..., 2.2286e+00,\n",
      "           3.1248e+00, 2.5956e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]]]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# load the model output / tensor from file:\n",
    "y_pred_loaded = torch.load('output_fftradnet_upto_rangeangle_model_014606.pt')\n",
    "print(y_pred_loaded.shape)\n",
    "print(y_pred_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn1.bias\n",
      "torch.Size([144])\n",
      "tensor([ 0.0241, -0.0140,  0.0318,  0.0055, -0.0433, -0.0232, -0.0399, -0.0247,\n",
      "         0.0386, -0.0121, -0.0513,  0.0499, -0.0461, -0.0028,  0.0389, -0.0214,\n",
      "        -0.0252,  0.0398, -0.0520,  0.0248, -0.0237, -0.0544, -0.0455, -0.0498,\n",
      "        -0.0046,  0.0292, -0.0573, -0.0514, -0.0181,  0.0491,  0.0282, -0.0658,\n",
      "        -0.0457,  0.0176,  0.0243, -0.0161,  0.0257,  0.0450, -0.0004,  0.0265,\n",
      "        -0.0367, -0.0466, -0.0155,  0.0499, -0.0300, -0.0211,  0.0347, -0.0661,\n",
      "        -0.0032, -0.0265,  0.0077,  0.0948, -0.0142,  0.0069, -0.0477,  0.0751,\n",
      "         0.0141,  0.0349, -0.0080,  0.0357,  0.0217,  0.0090,  0.0247, -0.0121,\n",
      "         0.0455,  0.0324,  0.0509, -0.0465,  0.0391,  0.0232,  0.0143,  0.0141,\n",
      "        -0.0418,  0.0272,  0.0053,  0.0139, -0.0306,  0.0127, -0.0998, -0.0238,\n",
      "         0.0345,  0.0634,  0.0393,  0.0288, -0.0009,  0.0194, -0.0703, -0.0367,\n",
      "         0.0174,  0.1173,  0.0056, -0.0474,  0.0518,  0.0398,  0.0028, -0.0575,\n",
      "        -0.0089, -0.0479,  0.0203, -0.0023,  0.0373, -0.0308,  0.0665, -0.0271,\n",
      "        -0.0293,  0.0448,  0.0310,  0.0143, -0.0294,  0.0243,  0.0143,  0.0963,\n",
      "         0.0477, -0.0075, -0.0149,  0.0306, -0.0233, -0.0315,  0.0144, -0.0157,\n",
      "         0.0472,  0.0494,  0.0436, -0.0346, -0.0728,  0.0127, -0.0182,  0.0334,\n",
      "         0.0284,  0.0169,  0.0011,  0.0396,  0.0280, -0.0391,  0.0219, -0.0248,\n",
      "         0.0124,  0.0305, -0.0266, -0.0193, -0.0132,  0.0401, -0.0247,  0.0018],\n",
      "       device='cuda:0')\n",
      "bn1.num_batches_tracked\n",
      "torch.Size([])\n",
      "tensor(123082, device='cuda:0')\n",
      "bn1.running_mean\n",
      "torch.Size([144])\n",
      "tensor([ 1.3192e+00,  1.7490e-01, -8.2151e-01,  6.1927e-01,  5.6923e-02,\n",
      "        -1.3441e+00,  2.1858e-01, -3.1203e-01, -1.6538e+00, -1.7092e+00,\n",
      "        -1.4159e+00, -1.3128e-01,  1.9768e+00,  3.0423e-01, -4.5077e-01,\n",
      "         2.6623e-01, -4.3209e-01, -3.7215e-01,  9.0694e-01, -8.1569e-01,\n",
      "         1.2809e+00, -2.7814e+00,  3.5377e-01, -1.4727e-01,  1.6617e+00,\n",
      "        -8.6503e-01,  3.9918e-01, -8.8790e-02,  5.4354e-01, -3.4499e-01,\n",
      "        -6.9447e-01, -2.6378e+00, -2.3455e-01, -1.5842e-01, -1.5801e+00,\n",
      "         5.8599e-01, -6.3473e-01,  3.3596e-01,  4.2350e-01, -1.8901e-01,\n",
      "        -1.1955e-01, -4.5620e-02,  7.0976e-01, -5.8100e-01, -1.6816e+00,\n",
      "        -1.7951e-01,  5.9743e-03, -3.1303e-01,  1.0675e-01, -1.3755e-02,\n",
      "         1.1411e-01, -3.1097e-02, -4.4935e-01, -3.1789e-01,  5.2224e-02,\n",
      "         2.5846e-01, -5.4484e-01, -3.1343e-01,  9.7074e-01,  6.5305e-02,\n",
      "         3.1920e-01,  4.5195e-01, -1.5367e-01, -4.3454e-01,  1.5916e-01,\n",
      "        -1.7188e+00,  3.5698e-01,  1.6882e-01,  3.1527e-01,  4.9389e-01,\n",
      "         4.1835e-01,  5.9605e-01, -3.6113e-02, -5.0382e-01,  2.6700e+00,\n",
      "         5.5965e-01, -7.3113e-01,  9.7498e-01, -3.7430e-01, -1.4496e-01,\n",
      "        -1.9474e-01,  2.8252e-03, -3.6382e-01,  1.0789e-01, -2.3051e+00,\n",
      "        -2.0889e+00, -7.0478e-02, -3.8169e-01, -3.9354e-01, -2.8298e-01,\n",
      "        -2.7815e-01,  1.0776e-01,  6.0506e-01, -1.5443e+00, -5.4443e-01,\n",
      "        -1.3296e-01,  1.1217e-01, -7.5248e-01, -1.6550e+00, -1.3619e+00,\n",
      "        -2.4443e-01, -1.3293e-01, -4.8916e-01,  8.9130e-01,  7.0786e-01,\n",
      "         3.4107e-01, -2.0161e+00, -3.7944e-02, -1.7510e-01, -7.0922e-02,\n",
      "        -1.0056e+00,  9.3531e-01, -1.0605e-01, -9.6251e-01, -7.0059e-02,\n",
      "        -5.4465e-01, -1.1278e+00,  1.0873e+00, -1.1328e+00, -2.8201e-01,\n",
      "        -7.3779e-01, -3.0151e-01,  1.2267e+00,  2.3143e-01, -1.2670e+00,\n",
      "        -4.8351e-01,  1.0986e+00,  2.2664e-01,  1.0426e-01, -3.6893e+00,\n",
      "         9.4079e-01,  4.2070e-02,  1.3701e-01,  5.8145e-02,  3.1543e-02,\n",
      "        -1.2158e+00,  9.2347e-03,  1.1436e-01,  2.3238e+00, -7.4786e-02,\n",
      "         2.1212e-03, -7.1577e-02, -1.5119e-01, -1.1084e+00], device='cuda:0')\n",
      "bn1.running_var\n",
      "torch.Size([144])\n",
      "tensor([20.9691, 21.7233, 46.8590, 27.2391,  1.5152, 43.0180,  4.9991, 36.0112,\n",
      "        58.4869, 63.1117, 30.6044, 14.2711, 69.6958,  2.9874, 41.8258,  2.3034,\n",
      "        15.0141,  1.0837, 32.9225, 54.4647, 57.3797,  6.2520, 15.3272,  6.3697,\n",
      "        39.3941, 54.6128, 19.0220, 30.7343,  8.8248,  2.1356, 21.9960, 23.5121,\n",
      "        17.2202, 46.0281, 70.2375, 42.0881, 38.4566,  3.7425, 43.9752, 21.8163,\n",
      "         9.7169, 17.9324, 48.1228, 30.0885, 71.3228, 14.8713, 37.6303, 10.2429,\n",
      "        35.7850, 12.7591, 23.9453, 28.2377, 18.1614, 22.8194,  6.2056, 17.5049,\n",
      "        30.0083,  2.6730, 16.5098, 21.8140, 16.5125, 26.3818,  4.5150, 12.3483,\n",
      "        18.8406, 75.0112,  0.6796, 46.2674, 11.0404, 43.4961, 37.8334, 36.8081,\n",
      "        29.4596, 24.7169, 42.5927, 20.0349,  9.9038, 68.9042, 11.5923,  4.4050,\n",
      "        19.1960, 43.9238,  2.5882, 13.5605, 50.1570, 60.3689,  5.4118, 29.9662,\n",
      "         1.1223, 18.9982, 10.6848, 13.1905, 16.9837, 40.6205, 37.3097, 12.6367,\n",
      "        12.8631, 12.0952, 19.6394, 30.6764, 23.9698, 30.8982,  2.7139, 49.7656,\n",
      "         1.4546,  3.5081, 34.3614, 31.7848,  7.6275,  5.0217, 62.7952, 25.3628,\n",
      "        15.2852, 22.5350, 13.3564, 35.6055, 28.4738, 56.6771, 26.5846, 20.0964,\n",
      "        17.2882,  1.5616, 48.1631, 27.2718, 40.6300, 20.2672, 46.0009, 20.8283,\n",
      "        21.5507, 83.5599, 38.8038,  3.6254, 27.5974, 49.9703, 15.0497, 18.5879,\n",
      "        27.6993, 45.6799, 28.5186, 36.9392, 16.0992,  3.7289, 13.3492, 10.1055],\n",
      "       device='cuda:0')\n",
      "bn1.weight\n",
      "torch.Size([144])\n",
      "tensor([1.0203, 0.9982, 0.9787, 0.9517, 1.0197, 0.9917, 0.9976, 1.0154, 0.9435,\n",
      "        0.9679, 0.9552, 1.0027, 0.9759, 1.0118, 1.0318, 1.0327, 0.9932, 1.0168,\n",
      "        0.9793, 0.9994, 0.9642, 1.0247, 0.9724, 1.0047, 0.9789, 0.9819, 1.0120,\n",
      "        0.9709, 1.0314, 0.9980, 0.9866, 1.0019, 1.0144, 0.9887, 0.9795, 0.9495,\n",
      "        0.9388, 1.0187, 0.9980, 1.0104, 1.0011, 1.0067, 1.0150, 0.9590, 0.9585,\n",
      "        0.9817, 1.0283, 1.0046, 0.9769, 1.0102, 0.9859, 0.9834, 1.0048, 1.0121,\n",
      "        1.0222, 0.9838, 0.9452, 1.0492, 1.0046, 0.9902, 0.9905, 0.9949, 1.0127,\n",
      "        0.9835, 1.0028, 0.9843, 1.0331, 1.0361, 0.9840, 0.9836, 0.9381, 0.9483,\n",
      "        0.9922, 0.9847, 1.0061, 0.9667, 1.0077, 0.9116, 0.9820, 1.0352, 0.9586,\n",
      "        1.0451, 1.0349, 1.0050, 0.9729, 1.0044, 1.0072, 1.0059, 1.0221, 0.9929,\n",
      "        0.9971, 0.9800, 1.0102, 1.0029, 0.9887, 1.0026, 1.0022, 1.0101, 0.9931,\n",
      "        0.9816, 0.9892, 0.9528, 1.0315, 1.0081, 1.0147, 1.0318, 0.9753, 0.9905,\n",
      "        1.0250, 1.0286, 0.9872, 0.9713, 0.9882, 0.9845, 1.0050, 0.9590, 1.0567,\n",
      "        0.9994, 0.9763, 1.0119, 1.0028, 1.0296, 0.9769, 0.9962, 0.9630, 0.9898,\n",
      "        1.0079, 0.9840, 1.0120, 0.9582, 0.9147, 1.0117, 0.9969, 1.0173, 0.9917,\n",
      "        0.9948, 0.9753, 1.0190, 0.9927, 0.9732, 0.9961, 1.0031, 1.0131, 0.9998],\n",
      "       device='cuda:0')\n",
      "bn2.bias\n",
      "torch.Size([96])\n",
      "tensor([ 0.0194, -0.0074, -0.0117,  0.0293,  0.0242, -0.0173, -0.0289,  0.0353,\n",
      "         0.0117, -0.0091, -0.0317, -0.0904, -0.0091, -0.0453,  0.0465, -0.0278,\n",
      "         0.0600, -0.0084, -0.0311, -0.0057,  0.0200,  0.0408, -0.0045,  0.0787,\n",
      "         0.0383,  0.0490,  0.0478,  0.0250,  0.0112,  0.0380, -0.0220,  0.0421,\n",
      "         0.0304, -0.0577, -0.0284,  0.0355, -0.0433,  0.0498,  0.0139, -0.0730,\n",
      "        -0.0476, -0.0436, -0.0131,  0.0187, -0.0144, -0.0469,  0.0044, -0.0184,\n",
      "        -0.0050, -0.0411,  0.0334, -0.0389,  0.0196,  0.0377,  0.0219,  0.0416,\n",
      "        -0.0241,  0.0169, -0.0054,  0.0371, -0.0203,  0.0179, -0.0337, -0.0291,\n",
      "         0.0187,  0.0552, -0.0062,  0.0150,  0.0395, -0.0300,  0.0351, -0.0114,\n",
      "         0.0435, -0.0128, -0.0588, -0.0319, -0.0297,  0.0015,  0.0370, -0.0397,\n",
      "         0.0323, -0.0651, -0.0194, -0.0142,  0.0003,  0.0158, -0.0317, -0.0391,\n",
      "        -0.0143, -0.0132, -0.0018, -0.0011,  0.0117,  0.0321,  0.0421, -0.0041],\n",
      "       device='cuda:0')\n",
      "bn2.num_batches_tracked\n",
      "torch.Size([])\n",
      "tensor(123082, device='cuda:0')\n",
      "bn2.running_mean\n",
      "torch.Size([96])\n",
      "tensor([-0.0743, -0.0115, -0.1605, -0.0767,  0.1297, -0.0671,  0.0837,  0.2671,\n",
      "        -0.1329,  0.1037,  0.0476, -0.0243,  0.0745, -0.1458, -0.0222,  0.0551,\n",
      "        -0.0829, -0.0436, -0.2733, -0.0854,  0.2304,  0.0193, -0.0132, -0.0284,\n",
      "         0.0286,  0.0854, -0.0678,  0.1872,  0.0720,  0.1694, -0.1368,  0.1254,\n",
      "         0.1984,  0.0598,  0.0577,  0.3584, -0.1344, -0.0228,  0.1270, -0.0291,\n",
      "         0.0494, -0.0355, -0.3160, -0.2107,  0.0094, -0.1131, -0.1518, -0.4484,\n",
      "        -0.1470, -0.0573,  0.2237, -0.3150,  0.1730,  0.3280,  0.0672,  0.1199,\n",
      "         0.0400, -0.0585,  0.0179,  0.1789, -0.0221, -0.0494,  0.0779, -0.1887,\n",
      "        -0.0772, -0.0267,  0.0319, -0.0256,  0.0059,  0.2128,  0.4048, -0.0393,\n",
      "        -0.0634,  0.0027, -0.1838, -0.4580,  0.0367, -0.0921,  0.0987, -0.3490,\n",
      "         0.0082,  0.0712, -0.1843, -0.0480, -0.1104,  0.1472, -0.1547,  0.1186,\n",
      "        -0.3012,  0.0991,  0.0541,  0.3026, -0.0953, -0.0293,  0.1735, -0.1668],\n",
      "       device='cuda:0')\n",
      "bn2.running_var\n",
      "torch.Size([96])\n",
      "tensor([14.6689, 10.9596, 52.9344, 41.0885, 40.0092, 54.4395, 49.8962, 55.2049,\n",
      "        56.1690, 12.2007, 31.5335, 28.8775,  8.5352, 29.8360,  0.5347,  2.0299,\n",
      "        34.9515, 52.6752, 38.7871, 26.6757, 46.1962, 36.5363, 20.2758, 49.5916,\n",
      "         6.4860, 37.3234, 13.4754, 53.6441, 21.2078, 10.7180, 30.0335, 24.5262,\n",
      "        32.6723, 36.5221, 32.0155, 52.6943, 32.4634, 55.7758, 43.8310,  9.1901,\n",
      "        33.4198,  3.9337, 49.4512, 24.8873, 10.2070, 24.8003, 30.1943, 45.7689,\n",
      "        78.0375,  6.3134, 40.1016, 48.6899, 44.2955, 45.4269, 13.9507,  5.2223,\n",
      "         5.3646, 10.2134, 38.5538, 16.3712, 70.5671, 57.8333, 18.3785, 50.9512,\n",
      "         9.6946, 39.8721, 14.1077, 19.9558, 52.1104, 29.0468, 37.9986, 30.9645,\n",
      "         5.1828, 14.8292, 18.0711, 37.3474, 38.4045, 27.6515,  7.4990, 29.4823,\n",
      "        37.8820, 52.4516, 55.9274, 61.1367,  7.1709, 34.0618, 24.6030, 18.5965,\n",
      "        50.9301, 14.0378,  5.3906, 32.9519,  9.3366, 34.1634, 46.6406, 46.9982],\n",
      "       device='cuda:0')\n",
      "bn2.weight\n",
      "torch.Size([96])\n",
      "tensor([1.0115, 1.0149, 1.0118, 1.0105, 0.9532, 0.9837, 0.9914, 0.9997, 0.9535,\n",
      "        0.9870, 0.9929, 0.9573, 1.0271, 0.9913, 1.0717, 1.0308, 0.9463, 0.9857,\n",
      "        1.0074, 0.9795, 0.9789, 0.9487, 1.0181, 0.9590, 1.0080, 0.9469, 0.9690,\n",
      "        0.9696, 0.9886, 1.0177, 0.9430, 0.9810, 1.0173, 0.9674, 0.9738, 1.0117,\n",
      "        0.9737, 0.9725, 0.9279, 1.0067, 0.9709, 1.0170, 1.0405, 1.0053, 1.0050,\n",
      "        0.9767, 0.9422, 1.0230, 0.9369, 1.0129, 1.0120, 1.0472, 0.9944, 0.9822,\n",
      "        1.0108, 1.0160, 1.0093, 1.0084, 0.9646, 1.0039, 0.9775, 0.9977, 0.9989,\n",
      "        1.0111, 0.9932, 0.9632, 1.0185, 0.9991, 0.9577, 1.0067, 1.0259, 1.0031,\n",
      "        1.0267, 1.0009, 0.9982, 1.0285, 0.9962, 1.0025, 1.0314, 1.0091, 0.9671,\n",
      "        0.9904, 0.9702, 0.9610, 1.0201, 0.9933, 0.9678, 0.9947, 1.0020, 0.9585,\n",
      "        1.0155, 1.0044, 1.0157, 0.9864, 1.0013, 0.9641], device='cuda:0')\n",
      "bn3.bias\n",
      "torch.Size([96])\n",
      "tensor([ 2.6680e-02, -3.8958e-02, -1.2214e-03,  5.9404e-02,  4.4256e-02,\n",
      "        -1.6780e-04, -3.1934e-02, -3.4169e-02, -3.9047e-02,  1.7037e-02,\n",
      "         4.4213e-02, -3.1616e-02,  2.9964e-02, -1.4726e-02, -1.5398e-02,\n",
      "        -5.3397e-02,  3.0071e-02, -8.4344e-02, -4.6850e-02, -5.7859e-02,\n",
      "        -1.3692e-03, -7.9040e-02, -1.7087e-02, -2.2855e-03, -3.7534e-02,\n",
      "         7.5110e-02, -5.8057e-02,  3.1934e-02,  3.1487e-02, -3.8639e-02,\n",
      "         8.3238e-02,  1.0982e-02, -1.4482e-02,  3.7666e-02,  3.9271e-02,\n",
      "         2.1021e-02,  7.1425e-02,  1.3541e-02, -1.4704e-02, -1.5413e-02,\n",
      "        -2.3351e-02,  3.0518e-02,  3.9989e-02,  1.6319e-02, -2.1387e-02,\n",
      "        -5.8925e-02, -2.2543e-02,  3.5068e-02, -1.4028e-02,  3.9401e-02,\n",
      "        -3.2338e-02, -2.1443e-02, -6.6556e-02, -2.6185e-02,  5.6084e-02,\n",
      "         5.7658e-03,  6.8600e-02, -4.9700e-02, -4.2030e-02,  2.4275e-02,\n",
      "         2.7237e-02, -2.3926e-02,  4.8260e-02,  2.6226e-02,  4.8901e-03,\n",
      "        -2.4210e-02,  2.7270e-02, -3.3430e-02,  2.3951e-02,  2.1597e-02,\n",
      "         7.5308e-02,  1.1251e-02,  3.4658e-02, -5.2570e-02, -2.5341e-02,\n",
      "        -1.5779e-03, -2.6174e-02, -5.7207e-05, -2.3355e-03, -3.8141e-02,\n",
      "        -4.9639e-03,  1.5611e-02, -3.7819e-02,  2.5571e-02, -2.6580e-02,\n",
      "         5.6733e-02, -2.8123e-02, -3.2648e-02, -8.6959e-02, -5.2268e-03,\n",
      "         3.0225e-02, -6.4644e-03,  1.5568e-02, -1.7784e-02,  2.2766e-03,\n",
      "        -1.1528e-01], device='cuda:0')\n",
      "bn3.num_batches_tracked\n",
      "torch.Size([])\n",
      "tensor(123082, device='cuda:0')\n",
      "bn3.running_mean\n",
      "torch.Size([96])\n",
      "tensor([ 1.4942e-01, -1.3222e-01,  1.2175e-01, -1.5913e-01, -7.8058e-02,\n",
      "         4.2827e-03, -5.9619e-02, -1.1561e-01, -1.3864e-02,  2.0971e-02,\n",
      "         1.0570e-01,  2.1302e-02, -1.3784e-02,  1.2286e-02,  5.8809e-02,\n",
      "        -1.5933e-01,  5.3746e-02,  1.0523e-01,  8.9198e-02,  7.5296e-02,\n",
      "         2.2202e-03,  1.3093e-01,  3.2966e-01, -1.7917e-01, -1.7793e-02,\n",
      "        -3.5768e-02, -2.9379e-02, -8.8458e-02,  1.7772e-01, -3.2494e-02,\n",
      "        -1.0152e-01,  1.0817e-01,  5.4688e-03, -6.4822e-02,  1.4984e-01,\n",
      "        -5.3301e-02,  2.5391e-01, -1.4969e-01,  5.5536e-03, -5.5123e-02,\n",
      "        -2.8439e-01, -5.6192e-02, -9.0652e-02, -1.3154e-01,  7.9204e-03,\n",
      "        -2.3924e-02, -1.2974e-01,  2.3813e-02, -1.1114e-01, -1.7135e-01,\n",
      "        -1.6232e-01,  1.5390e-01,  1.2061e-02,  2.2445e-03,  2.3692e-02,\n",
      "        -1.8277e-01, -1.3455e-01,  8.2185e-03, -1.1537e-03,  5.6442e-02,\n",
      "         1.6378e-01,  4.2783e-02,  3.8710e-02, -2.8492e-02, -3.9757e-02,\n",
      "        -1.5991e-01, -1.8498e-01, -5.6982e-02,  2.4559e-01,  1.5970e-03,\n",
      "        -4.1345e-02, -1.4696e-02,  8.4786e-02, -2.6867e-01, -1.4673e-01,\n",
      "        -2.3142e-01,  9.5704e-02, -5.2686e-02,  8.8233e-02,  8.6523e-02,\n",
      "         5.3146e-02,  5.0482e-03,  1.1276e-01, -4.6807e-02,  3.5367e-02,\n",
      "         1.6300e-02,  2.4901e-01,  1.7817e-04, -1.0867e-02,  2.4216e-01,\n",
      "         7.9451e-02,  1.8156e-01,  8.7204e-02, -7.9388e-02, -1.9356e-01,\n",
      "         1.2460e-01], device='cuda:0')\n",
      "bn3.running_var\n",
      "torch.Size([96])\n",
      "tensor([15.4402, 17.8708, 28.7553, 14.3112, 14.6348, 21.2975,  6.2547, 22.4365,\n",
      "        20.9232,  8.2636, 27.6818, 22.1849,  9.9201, 25.9859, 14.5605, 25.9297,\n",
      "        11.9505, 21.2592, 17.1696, 14.4900,  7.9078, 22.6451,  5.2845,  7.4710,\n",
      "         9.7444, 18.7610,  9.1042, 12.4560, 10.8029, 26.9605, 20.2235, 14.8946,\n",
      "        14.9792, 15.4461, 19.8709, 22.3212, 21.5238, 22.4591,  0.5989,  0.4575,\n",
      "        24.2329, 23.5039,  4.1974, 16.0751,  3.6436, 12.3136, 22.3247, 23.8640,\n",
      "        23.5023, 23.1136, 31.3919, 14.4470,  1.2734, 28.7740, 41.0025, 17.2184,\n",
      "        33.2570, 20.7795,  9.3666,  7.6458,  9.2292,  1.0260, 18.4251, 22.4583,\n",
      "        28.4671, 15.8187,  6.0620, 18.4398, 23.1688, 17.6292, 18.8020, 26.8769,\n",
      "        28.7597, 16.4613,  5.4952, 17.9521, 15.4572, 13.2270, 12.2777, 24.9161,\n",
      "         8.3150, 18.2000, 10.1676,  9.2430, 15.6036, 18.5235,  7.4059,  8.0137,\n",
      "        19.1012, 13.1128, 25.4539, 16.2239,  6.0903, 16.7784, 26.0256, 17.5051],\n",
      "       device='cuda:0')\n",
      "bn3.weight\n",
      "torch.Size([96])\n",
      "tensor([1.0014, 0.9948, 1.0186, 1.0032, 1.0023, 0.9683, 1.0324, 0.9929, 0.9828,\n",
      "        1.0271, 1.0045, 0.9937, 0.9902, 0.9849, 1.0116, 1.0083, 0.9820, 0.9443,\n",
      "        0.9745, 0.9855, 0.9942, 0.9738, 1.0193, 0.9885, 1.0130, 0.9805, 0.9751,\n",
      "        0.9995, 1.0190, 0.9977, 0.9869, 0.9861, 1.0042, 0.9671, 1.0298, 0.9718,\n",
      "        1.0671, 1.0016, 1.0145, 1.0514, 1.0317, 0.9503, 1.0104, 0.9976, 1.0082,\n",
      "        0.9816, 1.0033, 0.9534, 1.0248, 0.9604, 0.9840, 0.9898, 1.0483, 1.0057,\n",
      "        0.9725, 0.9940, 0.9399, 1.0051, 1.0131, 1.0097, 1.0066, 1.0317, 0.9935,\n",
      "        0.9743, 0.9623, 1.0158, 0.9884, 0.9990, 1.0268, 1.0163, 0.9815, 0.9522,\n",
      "        1.0192, 0.9863, 0.9916, 0.9712, 0.9814, 0.9887, 0.9901, 0.9918, 1.0058,\n",
      "        0.9929, 0.9918, 0.9921, 1.0053, 0.9904, 0.9998, 0.9966, 0.9798, 0.9853,\n",
      "        0.9841, 1.0204, 0.9940, 1.0029, 1.0278, 0.9751], device='cuda:0')\n",
      "bn4.bias\n",
      "torch.Size([96])\n",
      "tensor([ 0.0993, -0.1010, -0.1005, -0.1169, -0.1279, -0.1640, -0.1211, -0.1606,\n",
      "        -0.1664,  0.0748,  0.0187,  0.1032,  0.1670, -0.1183,  0.2044, -0.0943,\n",
      "         0.1019, -0.1180, -0.0354,  0.1173, -0.0830, -0.1298, -0.0860,  0.0657,\n",
      "         0.0845, -0.1085,  0.1304, -0.1052,  0.1062,  0.0955,  0.1594, -0.1775,\n",
      "         0.1169, -0.0896,  0.1304,  0.1011, -0.1548,  0.0786,  0.1017, -0.0802,\n",
      "        -0.1377,  0.0994, -0.0976, -0.0924, -0.1606,  0.1470,  0.0737,  0.0750,\n",
      "        -0.0679, -0.1093, -0.0705,  0.0902, -0.0913,  0.1804, -0.0847, -0.1738,\n",
      "        -0.0963,  0.0712,  0.1211,  0.0778, -0.0777,  0.1128, -0.1651,  0.0743,\n",
      "         0.0664,  0.0575, -0.0868, -0.0681,  0.0994,  0.0490,  0.0884,  0.0796,\n",
      "        -0.0916, -0.2301,  0.1041,  0.0803,  0.1871, -0.1096,  0.1236, -0.0836,\n",
      "         0.0925, -0.0462, -0.1181, -0.1501, -0.1462, -0.0690, -0.0496,  0.1539,\n",
      "         0.0835, -0.0810, -0.1011,  0.1350, -0.1710,  0.1367, -0.0954, -0.0970],\n",
      "       device='cuda:0')\n",
      "bn4.num_batches_tracked\n",
      "torch.Size([])\n",
      "tensor(123082, device='cuda:0')\n",
      "bn4.running_mean\n",
      "torch.Size([96])\n",
      "tensor([ 0.2371, -0.1203, -0.1759, -0.2068, -0.1898, -0.1679,  0.0177, -0.3545,\n",
      "        -0.3111, -0.2030, -0.0427, -0.1250,  0.0985, -0.2822,  0.0365,  0.0237,\n",
      "         0.4172, -0.2923, -0.0574, -0.0640,  0.0560, -0.1160,  0.0790,  0.1647,\n",
      "         0.2066,  0.1406,  0.0954, -0.0568,  0.0642,  0.2699,  0.2085, -0.0222,\n",
      "         0.2513,  0.0582, -0.0542, -0.0707,  0.0083,  0.3007,  0.0690, -0.2539,\n",
      "         0.1051, -0.1332,  0.0348, -0.0040, -0.3110,  0.0076,  0.1501,  0.2641,\n",
      "         0.0166, -0.0077, -0.2806, -0.0133, -0.0394,  0.3051,  0.0184, -0.0363,\n",
      "        -0.2890,  0.1801, -0.0820,  0.0168, -0.2357, -0.1284, -0.0896,  0.2665,\n",
      "        -0.1164, -0.1016, -0.3499, -0.2318, -0.0107, -0.1014, -0.1217,  0.0244,\n",
      "         0.0258, -0.0553,  0.0533,  0.3305, -0.0781, -0.0303, -0.0314,  0.1491,\n",
      "        -0.2138,  0.2479, -0.1034, -0.1784, -0.0489,  0.1356, -0.0328,  0.1546,\n",
      "         0.3435, -0.0655, -0.1762,  0.3321, -0.2975,  0.0645, -0.0135, -0.1113],\n",
      "       device='cuda:0')\n",
      "bn4.running_var\n",
      "torch.Size([96])\n",
      "tensor([35.0267, 34.3728,  8.9378, 28.3664,  9.5410, 11.3016, 11.0030, 27.7931,\n",
      "        24.6630, 18.5565,  9.3860, 12.0813, 16.9370, 34.1622, 10.1062, 21.7356,\n",
      "        20.5376, 21.2348, 28.9310, 17.1988, 16.3976, 10.0458, 17.7255, 22.2137,\n",
      "        29.8013,  2.6379, 16.1278, 32.3537, 27.3219, 26.4473, 17.5549, 10.7667,\n",
      "        32.3281,  5.4573, 11.7189,  8.9962, 13.6037, 36.1483,  7.9591, 23.7749,\n",
      "         7.4017, 17.5655, 13.1816,  4.9970, 23.6796, 20.9500, 27.9937, 37.4373,\n",
      "        24.5439, 20.9627, 32.3053, 17.0974, 12.5868, 15.8724, 24.8704,  8.1641,\n",
      "        26.0968, 28.1218, 17.9255, 14.2339, 37.5883, 13.3770, 12.8591, 40.3184,\n",
      "        19.1159, 17.9187, 35.7797, 40.2766, 14.3426, 30.9678, 17.9554, 23.9884,\n",
      "        11.9164,  8.3717, 13.6527, 39.1394,  5.2713, 23.9358, 12.3063, 14.2887,\n",
      "        15.7333, 29.2134, 19.7720, 11.5925, 18.9394, 22.4991, 19.1402, 13.3136,\n",
      "        34.0077, 27.0793, 24.2634, 19.6626, 24.6803, 16.1468, 20.8130, 32.2637],\n",
      "       device='cuda:0')\n",
      "bn4.weight\n",
      "torch.Size([96])\n",
      "tensor([1.0553, 1.0483, 1.0560, 1.0748, 1.0869, 1.0934, 1.1183, 1.0818, 1.0646,\n",
      "        1.0660, 1.0366, 1.0531, 1.0740, 1.0510, 1.1178, 1.0473, 1.0811, 1.0771,\n",
      "        1.0467, 1.0609, 1.0416, 1.1136, 1.0285, 1.0515, 1.0555, 1.1104, 1.0663,\n",
      "        1.0422, 1.0509, 1.0618, 1.0668, 1.0918, 1.0692, 1.0819, 1.0951, 1.0656,\n",
      "        1.0917, 1.0577, 1.1183, 1.0597, 1.0967, 1.0692, 1.0736, 1.1073, 1.0525,\n",
      "        1.0701, 1.0334, 1.0277, 1.0721, 1.0412, 1.0429, 1.0554, 1.0692, 1.0800,\n",
      "        1.0483, 1.0977, 1.0646, 1.0324, 1.0644, 1.0777, 1.0456, 1.0518, 1.0554,\n",
      "        1.0402, 1.0195, 1.0385, 1.0582, 1.0308, 1.0869, 1.0415, 1.0386, 1.0289,\n",
      "        1.0680, 1.1025, 1.0577, 1.0422, 1.1142, 1.0507, 1.0892, 1.0429, 1.0533,\n",
      "        1.0680, 1.0632, 1.1045, 1.0793, 1.0594, 1.0558, 1.0676, 1.0362, 1.0449,\n",
      "        1.0666, 1.0787, 1.0816, 1.0637, 1.0322, 1.0462], device='cuda:0')\n",
      "clshead.bias\n",
      "torch.Size([1])\n",
      "tensor([-0.0328], device='cuda:0')\n",
      "clshead.weight\n",
      "torch.Size([1, 96, 3, 3])\n",
      "tensor([[[[-9.6813e-02, -1.4883e-01, -1.2381e-01],\n",
      "          [ 2.3773e-04, -7.7274e-02, -9.4490e-02],\n",
      "          [ 1.3541e-02, -3.4873e-02, -9.5532e-02]],\n",
      "\n",
      "         [[ 1.0076e-01,  8.4174e-02,  7.2163e-02],\n",
      "          [ 9.6343e-02,  1.8397e-02, -4.6655e-03],\n",
      "          [ 1.1814e-01,  4.1457e-02,  3.0942e-02]],\n",
      "\n",
      "         [[ 8.0852e-02,  7.9903e-02,  1.6335e-01],\n",
      "          [ 1.0245e-01,  1.3863e-01,  2.4985e-01],\n",
      "          [ 5.2334e-02, -4.0737e-02,  4.5395e-02]],\n",
      "\n",
      "         [[-5.3496e-02,  3.7056e-03,  4.7546e-02],\n",
      "          [ 3.3466e-02,  5.2092e-02,  8.3943e-02],\n",
      "          [ 1.2824e-01,  1.9071e-01,  1.4947e-01]],\n",
      "\n",
      "         [[-1.1523e-01,  4.3265e-02,  1.5053e-01],\n",
      "          [-1.3023e-01,  8.1938e-02,  3.2478e-01],\n",
      "          [-6.8365e-02,  8.2333e-02,  2.5048e-01]],\n",
      "\n",
      "         [[ 2.6404e-01,  2.0217e-01,  2.5241e-01],\n",
      "          [ 1.5454e-01,  2.2770e-02,  1.4097e-01],\n",
      "          [ 2.0323e-02, -1.0030e-01,  2.0369e-02]],\n",
      "\n",
      "         [[-2.8203e-02, -1.4768e-01, -1.1627e-01],\n",
      "          [ 1.0531e-01,  1.0430e-01,  6.1695e-02],\n",
      "          [ 2.1813e-01,  4.0170e-01,  3.7270e-01]],\n",
      "\n",
      "         [[ 1.0474e-01,  1.5823e-01,  8.1864e-02],\n",
      "          [ 1.3444e-01,  1.4281e-01,  1.3640e-02],\n",
      "          [ 1.1936e-01,  6.6989e-02,  4.9702e-02]],\n",
      "\n",
      "         [[ 1.0895e-01,  7.1014e-02, -3.0909e-03],\n",
      "          [ 1.0862e-01,  1.2958e-01, -1.1077e-03],\n",
      "          [ 1.5012e-01,  1.9648e-01,  1.1685e-01]],\n",
      "\n",
      "         [[-2.8098e-02,  2.8763e-02, -7.5759e-02],\n",
      "          [-2.3591e-02, -3.0083e-02, -1.9891e-01],\n",
      "          [-7.5801e-02, -1.0118e-01, -2.4729e-01]],\n",
      "\n",
      "         [[ 1.2518e-01,  4.7503e-02, -4.2820e-02],\n",
      "          [ 5.2884e-02, -1.3370e-01, -2.6142e-01],\n",
      "          [ 1.8512e-01,  2.2501e-02, -9.2342e-02]],\n",
      "\n",
      "         [[-2.1107e-01,  1.4994e-02, -1.5631e-01],\n",
      "          [-2.3416e-01,  5.1698e-02, -1.2805e-01],\n",
      "          [-2.9582e-01, -1.6168e-01, -3.1744e-01]],\n",
      "\n",
      "         [[-1.3422e-01, -1.3759e-01, -2.8804e-03],\n",
      "          [-9.7855e-02, -8.8584e-02,  8.7346e-03],\n",
      "          [-2.0857e-01, -3.6742e-01, -1.5378e-01]],\n",
      "\n",
      "         [[ 9.6260e-02,  1.2206e-01,  9.8483e-02],\n",
      "          [ 9.4740e-02,  1.0744e-01,  2.4984e-02],\n",
      "          [ 1.0813e-01,  7.2592e-02,  4.5408e-02]],\n",
      "\n",
      "         [[-2.3543e-01, -2.6134e-01, -3.4291e-01],\n",
      "          [-6.1781e-02, -9.8095e-02, -2.4861e-01],\n",
      "          [-1.9963e-01, -1.6181e-01, -3.7274e-01]],\n",
      "\n",
      "         [[ 2.2827e-01,  2.3735e-01,  1.5468e-01],\n",
      "          [ 9.5221e-02,  2.5193e-02, -1.0195e-01],\n",
      "          [ 1.4578e-01,  1.3845e-01,  2.8619e-02]],\n",
      "\n",
      "         [[-7.7216e-02, -7.7665e-02, -6.8211e-02],\n",
      "          [-1.7364e-02, -9.4171e-02, -1.6695e-01],\n",
      "          [-7.7672e-02, -1.5629e-01, -1.6469e-01]],\n",
      "\n",
      "         [[-1.1743e-01, -5.0078e-02, -1.7390e-02],\n",
      "          [-5.3894e-02,  1.1541e-01,  9.2154e-02],\n",
      "          [ 1.0342e-01,  2.9168e-01,  2.0187e-01]],\n",
      "\n",
      "         [[-7.4491e-02, -5.6082e-02, -5.7645e-02],\n",
      "          [ 5.7992e-02,  1.1297e-01,  3.7981e-02],\n",
      "          [ 8.1497e-02,  1.2280e-01,  5.9618e-02]],\n",
      "\n",
      "         [[-2.0335e-01, -8.9270e-02, -2.3838e-01],\n",
      "          [-1.7550e-01,  1.9423e-02, -2.1620e-01],\n",
      "          [-2.2784e-01, -7.6264e-02, -1.7400e-01]],\n",
      "\n",
      "         [[ 2.8351e-01,  8.9389e-02,  1.3201e-01],\n",
      "          [ 3.2152e-01,  2.6070e-02,  1.8457e-02],\n",
      "          [ 2.6935e-01, -2.4917e-07, -3.1580e-03]],\n",
      "\n",
      "         [[-8.0357e-02, -8.3412e-02, -4.6943e-02],\n",
      "          [ 1.7246e-02,  1.1372e-01,  9.5597e-02],\n",
      "          [ 2.6986e-01,  4.3060e-01,  2.2778e-01]],\n",
      "\n",
      "         [[ 2.5513e-01,  2.6509e-01,  2.1886e-01],\n",
      "          [ 2.1369e-02, -6.4847e-02, -5.3247e-02],\n",
      "          [ 1.2380e-01,  2.2590e-01,  2.0839e-01]],\n",
      "\n",
      "         [[-1.9716e-01, -2.3551e-01, -2.0138e-01],\n",
      "          [-3.7608e-02, -8.5339e-02, -1.4628e-01],\n",
      "          [ 9.1318e-02,  7.4858e-02,  2.5123e-02]],\n",
      "\n",
      "         [[ 3.3528e-02,  5.8170e-02, -1.0637e-01],\n",
      "          [-3.5093e-02, -6.7513e-02, -2.4137e-01],\n",
      "          [-1.1360e-01, -6.7247e-02, -1.4088e-01]],\n",
      "\n",
      "         [[-1.4132e-01, -1.4758e-01,  2.8538e-01],\n",
      "          [ 1.6270e-02, -2.7009e-03,  4.2250e-01],\n",
      "          [ 7.0180e-02, -5.6335e-04,  3.0468e-01]],\n",
      "\n",
      "         [[-2.2240e-01, -1.3287e-01, -1.6805e-01],\n",
      "          [-2.7932e-01, -3.3561e-02, -6.9740e-02],\n",
      "          [-1.3810e-01, -3.5231e-02, -2.3272e-02]],\n",
      "\n",
      "         [[ 1.0004e-01,  1.0322e-01,  1.4382e-01],\n",
      "          [ 1.0686e-01,  3.7814e-02,  1.7524e-01],\n",
      "          [ 1.8094e-01,  1.2898e-01,  1.7162e-01]],\n",
      "\n",
      "         [[-1.6708e-01, -1.1074e-01, -2.5496e-01],\n",
      "          [-1.6515e-01, -4.8989e-02, -2.2457e-01],\n",
      "          [-9.9595e-02, -9.2554e-02, -1.3853e-01]],\n",
      "\n",
      "         [[-4.3568e-02, -2.6171e-03, -2.7487e-02],\n",
      "          [-1.3329e-01, -1.3483e-01, -1.6595e-02],\n",
      "          [-1.5565e-01, -9.4649e-02, -1.0681e-01]],\n",
      "\n",
      "         [[-8.9931e-02, -1.6818e-01, -1.5726e-01],\n",
      "          [ 1.5694e-02, -3.1220e-02, -7.3526e-02],\n",
      "          [-1.1917e-01, -2.3906e-01, -1.7934e-01]],\n",
      "\n",
      "         [[ 2.0519e-01,  3.4690e-01,  2.6391e-01],\n",
      "          [ 4.7956e-03,  4.5622e-02,  1.4321e-01],\n",
      "          [ 2.2376e-01,  3.6795e-01,  3.0020e-01]],\n",
      "\n",
      "         [[-1.1916e-01, -1.1419e-01, -9.5002e-02],\n",
      "          [-8.2500e-02, -4.1459e-02,  2.9693e-02],\n",
      "          [-1.1385e-01, -1.0755e-01, -3.9113e-03]],\n",
      "\n",
      "         [[ 2.7563e-01,  1.3437e-01, -7.7523e-02],\n",
      "          [ 1.8017e-01, -1.4835e-02, -3.0711e-01],\n",
      "          [ 2.5927e-01,  2.1897e-01,  1.2456e-03]],\n",
      "\n",
      "         [[-9.2101e-02, -1.4327e-02, -1.2364e-01],\n",
      "          [-6.5764e-02,  4.1798e-02, -1.7099e-01],\n",
      "          [-2.4861e-01, -2.7641e-01, -3.4432e-01]],\n",
      "\n",
      "         [[-1.1022e-01, -1.3154e-01, -9.6867e-02],\n",
      "          [-3.3671e-02, -1.1639e-02, -5.0364e-02],\n",
      "          [-1.2355e-02, -7.1982e-02, -1.1217e-01]],\n",
      "\n",
      "         [[ 2.3323e-01,  2.4049e-01,  2.3866e-01],\n",
      "          [ 2.1476e-01,  1.0834e-01,  1.8658e-01],\n",
      "          [ 9.2013e-02, -8.8202e-02,  5.0807e-02]],\n",
      "\n",
      "         [[-3.6769e-02, -8.6788e-02, -1.1228e-01],\n",
      "          [ 1.3520e-02, -2.1715e-02, -1.4552e-01],\n",
      "          [ 4.3592e-03, -9.6318e-02, -1.6455e-01]],\n",
      "\n",
      "         [[-1.3279e-01, -4.1132e-01, -2.3291e-01],\n",
      "          [-4.9390e-02, -1.9714e-01, -1.9398e-01],\n",
      "          [ 2.9642e-01,  2.2079e-01, -2.5668e-03]],\n",
      "\n",
      "         [[ 1.6525e-01,  1.1355e-01,  2.5907e-02],\n",
      "          [ 2.8292e-01,  8.4950e-02, -2.7415e-02],\n",
      "          [ 1.0324e-01,  2.1442e-02, -8.5586e-02]],\n",
      "\n",
      "         [[ 1.0281e-01,  4.2279e-02,  2.8750e-01],\n",
      "          [ 5.7884e-02, -1.2033e-01,  1.7830e-01],\n",
      "          [ 2.9175e-01,  2.8843e-01,  3.2714e-01]],\n",
      "\n",
      "         [[-1.5562e-01, -6.6886e-02, -1.9179e-01],\n",
      "          [-9.1589e-02,  1.0672e-02, -1.6752e-01],\n",
      "          [-3.2245e-03,  5.2841e-02, -1.4534e-01]],\n",
      "\n",
      "         [[ 1.9899e-01,  4.1258e-01,  2.0854e-01],\n",
      "          [ 5.9845e-02,  1.4595e-01,  1.1641e-01],\n",
      "          [-6.7967e-02, -2.1478e-01, -6.2939e-02]],\n",
      "\n",
      "         [[ 2.3819e-01,  5.8215e-02, -7.2408e-02],\n",
      "          [ 3.5503e-01,  2.7643e-02, -2.4127e-01],\n",
      "          [ 3.3932e-01,  4.6339e-02, -1.9343e-01]],\n",
      "\n",
      "         [[ 1.5725e-01,  8.7832e-02,  1.2166e-01],\n",
      "          [ 1.7406e-01,  9.4181e-02,  5.9763e-02],\n",
      "          [ 1.5784e-01,  9.3713e-02,  5.4215e-02]],\n",
      "\n",
      "         [[-9.8237e-02, -1.5901e-01, -9.9046e-02],\n",
      "          [-1.5443e-01, -6.5817e-02, -3.6008e-02],\n",
      "          [-1.9364e-01, -1.4302e-01, -6.6219e-02]],\n",
      "\n",
      "         [[-6.6609e-02,  3.0215e-02,  3.1879e-02],\n",
      "          [-1.1158e-01, -6.7268e-02,  9.3291e-03],\n",
      "          [-1.5860e-01, -1.7923e-01, -1.0827e-01]],\n",
      "\n",
      "         [[-9.1472e-02, -1.3698e-01, -7.7802e-02],\n",
      "          [-6.1896e-02, -1.1059e-01, -5.1063e-02],\n",
      "          [-3.8947e-02, -6.6411e-02,  1.0541e-02]],\n",
      "\n",
      "         [[-5.4901e-02, -1.5152e-01, -6.5268e-02],\n",
      "          [ 1.1883e-01,  6.4890e-02,  1.3234e-01],\n",
      "          [ 2.3079e-01,  2.3691e-01,  2.3396e-01]],\n",
      "\n",
      "         [[ 1.2521e-01,  2.1375e-01,  1.6963e-01],\n",
      "          [ 4.5547e-02, -1.0918e-02,  8.1193e-02],\n",
      "          [ 1.1717e-01,  1.0030e-01,  8.6961e-02]],\n",
      "\n",
      "         [[-5.0017e-02,  1.0835e-01,  1.0662e-01],\n",
      "          [-1.0393e-01,  1.0902e-01,  9.4432e-02],\n",
      "          [-6.9849e-02,  6.2731e-02,  1.6611e-03]],\n",
      "\n",
      "         [[-5.4538e-02,  7.0674e-02, -3.8444e-02],\n",
      "          [-9.7979e-02, -2.1374e-02, -8.9706e-02],\n",
      "          [-3.6983e-01, -3.0833e-01, -1.4843e-01]],\n",
      "\n",
      "         [[-1.3146e-02,  8.7941e-02,  8.2390e-02],\n",
      "          [-1.0670e-02,  6.6035e-02,  8.5153e-02],\n",
      "          [ 1.7246e-01,  2.7426e-01,  1.5771e-01]],\n",
      "\n",
      "         [[ 3.8073e-02, -1.1512e-02, -1.1991e-01],\n",
      "          [ 1.5510e-02, -7.9770e-02, -2.7149e-01],\n",
      "          [-9.9913e-02, -1.9031e-01, -2.0396e-01]],\n",
      "\n",
      "         [[ 5.6181e-02,  9.0710e-02,  1.5136e-01],\n",
      "          [-3.3261e-02,  3.1254e-03,  1.1673e-01],\n",
      "          [ 1.1784e-01,  2.6114e-01,  2.0354e-01]],\n",
      "\n",
      "         [[ 1.5676e-01,  1.7877e-01,  3.0007e-01],\n",
      "          [ 8.8300e-02,  6.3790e-02,  3.0742e-01],\n",
      "          [-7.2003e-02, -6.0802e-02,  2.8052e-01]],\n",
      "\n",
      "         [[ 1.3020e-01,  1.2858e-01,  1.5313e-01],\n",
      "          [ 6.4192e-02,  9.2272e-02,  8.5071e-02],\n",
      "          [ 5.3811e-02,  5.5747e-02,  2.4380e-02]],\n",
      "\n",
      "         [[-9.3280e-02, -1.5446e-01, -7.5446e-02],\n",
      "          [-6.2297e-02, -1.0260e-01, -5.1155e-02],\n",
      "          [-2.6969e-02, -8.4079e-02, -3.4964e-02]],\n",
      "\n",
      "         [[-2.2135e-01, -9.8691e-02, -8.5163e-02],\n",
      "          [-2.6105e-01, -2.8067e-02,  1.9675e-02],\n",
      "          [-1.6603e-01,  5.8219e-03,  5.5220e-02]],\n",
      "\n",
      "         [[ 1.1301e-01,  2.0123e-01,  5.1829e-02],\n",
      "          [-1.0305e-01, -7.2136e-02, -1.4569e-01],\n",
      "          [-2.7469e-01, -2.7756e-01, -2.2570e-01]],\n",
      "\n",
      "         [[ 9.9351e-02,  1.5171e-01,  9.1632e-02],\n",
      "          [-1.1603e-02,  7.2598e-02,  8.7226e-03],\n",
      "          [ 1.0134e-01,  1.1742e-01,  2.0595e-02]],\n",
      "\n",
      "         [[-1.7405e-01, -3.0403e-02, -1.4393e-01],\n",
      "          [-2.2221e-01,  7.1229e-02,  4.9029e-02],\n",
      "          [-3.0704e-01, -1.2595e-01, -1.8192e-01]],\n",
      "\n",
      "         [[-1.4268e-02,  1.3286e-01,  1.5005e-01],\n",
      "          [-7.0545e-02,  1.1129e-01,  1.7483e-01],\n",
      "          [ 5.6704e-02,  1.2315e-01,  1.8694e-01]],\n",
      "\n",
      "         [[-1.1217e-01, -6.6453e-02, -9.1122e-02],\n",
      "          [-8.4501e-02, -8.2690e-02, -3.7473e-02],\n",
      "          [-7.5394e-02, -6.4177e-02, -6.6119e-02]],\n",
      "\n",
      "         [[-9.3484e-02, -4.6893e-02, -9.7963e-02],\n",
      "          [-7.7288e-02,  2.7914e-02, -1.8454e-02],\n",
      "          [-1.1852e-01, -1.7242e-01, -1.2100e-01]],\n",
      "\n",
      "         [[-1.0405e-01, -7.5923e-02, -1.7157e-01],\n",
      "          [ 9.1995e-02, -2.5357e-03, -1.6064e-01],\n",
      "          [ 6.4965e-03, -8.2131e-02, -1.9943e-01]],\n",
      "\n",
      "         [[ 5.8648e-02,  6.6803e-02,  7.9148e-02],\n",
      "          [ 8.6898e-03,  8.4677e-02,  3.2410e-02],\n",
      "          [ 1.3229e-01,  2.1205e-01,  1.7230e-01]],\n",
      "\n",
      "         [[ 5.6635e-02,  9.3692e-03,  4.8484e-02],\n",
      "          [ 8.7739e-02,  1.0874e-01,  5.7697e-02],\n",
      "          [ 1.3524e-01,  1.1504e-01,  4.7816e-02]],\n",
      "\n",
      "         [[-1.8778e-01, -2.5824e-01, -2.5260e-01],\n",
      "          [-2.5212e-01, -3.5377e-02, -7.9081e-03],\n",
      "          [-8.0350e-02,  1.8349e-01,  1.1832e-01]],\n",
      "\n",
      "         [[-1.1940e-01, -1.0881e-01, -1.3574e-01],\n",
      "          [-1.3014e-01, -6.7000e-02, -8.5364e-02],\n",
      "          [-4.9617e-02,  8.2267e-02,  5.8178e-02]],\n",
      "\n",
      "         [[-2.1339e-01, -2.3847e-01, -2.3809e-01],\n",
      "          [-8.0069e-02,  5.0048e-02, -2.8754e-02],\n",
      "          [-2.9359e-01, -2.4358e-01, -1.4439e-01]],\n",
      "\n",
      "         [[-1.2858e-01, -1.4707e-01, -2.2866e-01],\n",
      "          [-8.2867e-02,  5.7412e-02, -1.6601e-01],\n",
      "          [-2.0881e-01, -1.8235e-01, -2.0408e-01]],\n",
      "\n",
      "         [[ 2.2030e-01,  3.0601e-01,  2.7611e-01],\n",
      "          [ 1.9955e-01, -9.6828e-03,  4.9289e-02],\n",
      "          [ 7.2475e-02, -2.1293e-01, -2.3518e-02]],\n",
      "\n",
      "         [[ 3.8463e-02, -4.6108e-02,  2.4479e-02],\n",
      "          [ 1.6191e-01,  1.0606e-01,  2.0219e-01],\n",
      "          [ 2.1283e-01,  2.0127e-01,  1.5459e-01]],\n",
      "\n",
      "         [[-1.1155e-02, -1.5043e-01, -1.8846e-01],\n",
      "          [ 1.9073e-01, -6.5077e-02, -2.3875e-01],\n",
      "          [ 4.5711e-02, -1.6116e-01, -2.5267e-01]],\n",
      "\n",
      "         [[-9.1800e-02, -6.0537e-02, -1.0235e-01],\n",
      "          [-8.9862e-02, -5.7809e-02, -6.3926e-02],\n",
      "          [-1.0309e-01, -8.2552e-02, -5.0126e-02]],\n",
      "\n",
      "         [[-2.1782e-01, -1.3582e-01, -2.3993e-01],\n",
      "          [-6.9886e-02,  1.1048e-01, -6.5277e-02],\n",
      "          [-3.5544e-01, -4.0331e-01, -3.3065e-01]],\n",
      "\n",
      "         [[ 1.8124e-01,  2.9681e-01,  1.9875e-01],\n",
      "          [ 9.9552e-03,  1.1834e-01,  8.9875e-02],\n",
      "          [ 1.1758e-02,  5.3364e-02,  3.8313e-02]],\n",
      "\n",
      "         [[-1.3024e-01, -2.3450e-01, -3.7559e-01],\n",
      "          [ 6.4825e-03, -1.0772e-01, -3.5446e-01],\n",
      "          [ 5.1793e-02, -1.9916e-03, -2.4674e-01]],\n",
      "\n",
      "         [[ 2.4440e-01,  3.2286e-03,  1.9846e-01],\n",
      "          [ 2.4624e-01, -5.2734e-02,  9.0013e-02],\n",
      "          [ 3.3188e-01,  4.8926e-02,  1.8339e-01]],\n",
      "\n",
      "         [[-2.0501e-01, -8.2499e-02, -2.2339e-01],\n",
      "          [-1.3063e-01,  1.7549e-01, -1.0221e-02],\n",
      "          [-2.3169e-01, -5.1387e-02, -1.1677e-01]],\n",
      "\n",
      "         [[-3.9403e-02, -1.0814e-01, -1.1024e-01],\n",
      "          [ 6.6360e-02,  4.5975e-02, -6.1172e-02],\n",
      "          [ 1.5372e-01,  1.3548e-01,  4.1405e-02]],\n",
      "\n",
      "         [[ 1.3740e-01,  6.4437e-02,  3.3111e-02],\n",
      "          [ 1.5279e-01, -1.3749e-02,  6.8268e-02],\n",
      "          [ 2.0111e-01,  1.7121e-01,  2.1304e-01]],\n",
      "\n",
      "         [[ 1.0075e-01,  2.2246e-01,  2.1684e-01],\n",
      "          [-2.4234e-02,  1.8097e-01,  2.8803e-01],\n",
      "          [-1.9338e-01, -7.8171e-02,  4.3110e-02]],\n",
      "\n",
      "         [[ 1.6284e-01,  3.5891e-01,  2.5636e-01],\n",
      "          [-6.9871e-03,  8.9370e-02,  1.4115e-01],\n",
      "          [-5.2203e-03,  1.8150e-01,  2.2003e-01]],\n",
      "\n",
      "         [[ 1.0641e-01,  2.0894e-02,  1.3199e-02],\n",
      "          [ 1.9326e-01, -4.8890e-02,  2.8858e-02],\n",
      "          [ 2.2262e-01,  1.2820e-01,  8.1733e-02]],\n",
      "\n",
      "         [[-3.4312e-02, -2.5635e-01, -1.0732e-01],\n",
      "          [ 1.6520e-01,  9.6587e-02,  1.0392e-01],\n",
      "          [ 1.4864e-01,  1.2651e-01,  8.5192e-02]],\n",
      "\n",
      "         [[-1.2497e-01, -2.9886e-01, -2.1972e-01],\n",
      "          [ 6.9559e-02, -8.3754e-02, -1.2680e-01],\n",
      "          [ 3.7125e-02, -1.3367e-01, -1.8099e-01]],\n",
      "\n",
      "         [[-1.0978e-01, -1.0685e-01, -2.9712e-02],\n",
      "          [-1.5821e-01, -9.2392e-02,  2.5538e-02],\n",
      "          [-1.3998e-01, -1.1237e-01, -3.1429e-02]],\n",
      "\n",
      "         [[ 2.2133e-01,  2.6912e-01,  2.3686e-01],\n",
      "          [ 1.5038e-01,  1.3920e-01,  8.2003e-02],\n",
      "          [ 1.0625e-01,  5.0010e-03, -6.6092e-02]],\n",
      "\n",
      "         [[ 8.0671e-02,  4.9057e-02, -4.1776e-03],\n",
      "          [ 1.3764e-01, -4.4544e-03,  5.3373e-02],\n",
      "          [ 1.5369e-01,  8.0956e-02,  8.8808e-02]],\n",
      "\n",
      "         [[-9.4169e-02, -6.0895e-02, -4.5334e-02],\n",
      "          [-1.4654e-01, -8.7508e-02, -1.6586e-02],\n",
      "          [-1.9431e-01, -1.0067e-01, -1.0247e-01]],\n",
      "\n",
      "         [[ 7.8539e-02,  1.1339e-01,  3.6322e-02],\n",
      "          [ 8.6375e-02,  1.6048e-01,  1.6061e-02],\n",
      "          [ 1.4550e-01,  1.4225e-01,  1.1923e-01]],\n",
      "\n",
      "         [[-7.2412e-02,  1.3928e-02, -9.9879e-02],\n",
      "          [-1.9786e-01, -4.0607e-02, -1.6950e-01],\n",
      "          [-1.7185e-01, -1.3705e-01, -1.7963e-01]],\n",
      "\n",
      "         [[ 1.4813e-01,  1.4676e-02,  1.8143e-01],\n",
      "          [ 2.3825e-01,  5.7596e-03,  1.8558e-01],\n",
      "          [ 2.2440e-01,  3.8620e-02,  1.6766e-01]],\n",
      "\n",
      "         [[ 1.1946e-01,  1.9037e-01,  1.3564e-01],\n",
      "          [ 2.0192e-02,  5.0675e-02,  5.8227e-02],\n",
      "          [ 3.7903e-02,  5.6527e-02,  9.0388e-02]]]], device='cuda:0')\n",
      "conv1.weight\n",
      "torch.Size([144, 256, 3, 3])\n",
      "tensor([[[[ 0.0232,  0.0207, -0.0018],\n",
      "          [ 0.0139, -0.0140,  0.0121],\n",
      "          [-0.0165, -0.0114, -0.0220]],\n",
      "\n",
      "         [[-0.0183,  0.0379, -0.0232],\n",
      "          [ 0.0090,  0.0125,  0.0019],\n",
      "          [ 0.0120,  0.0525,  0.0236]],\n",
      "\n",
      "         [[-0.0069, -0.0153,  0.0071],\n",
      "          [-0.0016,  0.0018,  0.0157],\n",
      "          [ 0.0121,  0.0307, -0.0111]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0405,  0.0193,  0.0202],\n",
      "          [ 0.0181,  0.0543,  0.0192],\n",
      "          [ 0.0428,  0.0173,  0.0193]],\n",
      "\n",
      "         [[ 0.0498,  0.0037,  0.0373],\n",
      "          [-0.0322, -0.0258,  0.0035],\n",
      "          [ 0.0172,  0.0243,  0.0184]],\n",
      "\n",
      "         [[-0.0445, -0.0162, -0.0264],\n",
      "          [-0.0047, -0.0143, -0.0073],\n",
      "          [ 0.0169,  0.0078, -0.0110]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0285,  0.0352,  0.0529],\n",
      "          [-0.0055,  0.0216,  0.0602],\n",
      "          [ 0.0392, -0.0037,  0.0215]],\n",
      "\n",
      "         [[-0.0213, -0.0654, -0.0449],\n",
      "          [-0.0207, -0.0582, -0.0280],\n",
      "          [-0.0365, -0.0490, -0.0020]],\n",
      "\n",
      "         [[-0.0196,  0.0119,  0.0051],\n",
      "          [ 0.0174,  0.0126, -0.0170],\n",
      "          [-0.0340, -0.0187, -0.0295]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0254, -0.0450,  0.0070],\n",
      "          [-0.0511, -0.0532, -0.0052],\n",
      "          [-0.0218, -0.0541,  0.0012]],\n",
      "\n",
      "         [[ 0.0180,  0.0427,  0.0036],\n",
      "          [-0.0246, -0.0155, -0.0298],\n",
      "          [-0.0185,  0.0103, -0.0056]],\n",
      "\n",
      "         [[ 0.0209,  0.0169,  0.0149],\n",
      "          [ 0.0192,  0.0237,  0.0015],\n",
      "          [-0.0092, -0.0064, -0.0175]]],\n",
      "\n",
      "\n",
      "        [[[-0.0044,  0.0073, -0.0295],\n",
      "          [-0.0025,  0.0208, -0.0076],\n",
      "          [-0.0320, -0.0075, -0.0265]],\n",
      "\n",
      "         [[ 0.0237,  0.0374, -0.0209],\n",
      "          [ 0.0342, -0.0019, -0.0427],\n",
      "          [ 0.0257,  0.0232, -0.0142]],\n",
      "\n",
      "         [[-0.0205, -0.0159, -0.0056],\n",
      "          [-0.0156,  0.0030, -0.0023],\n",
      "          [ 0.0225,  0.0379,  0.0185]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0110,  0.0162,  0.0204],\n",
      "          [ 0.0288,  0.0334,  0.0333],\n",
      "          [ 0.0222,  0.0118, -0.0078]],\n",
      "\n",
      "         [[ 0.0556,  0.0158,  0.0302],\n",
      "          [-0.0384, -0.0459, -0.0209],\n",
      "          [ 0.0097,  0.0141, -0.0063]],\n",
      "\n",
      "         [[-0.0345, -0.0214, -0.0346],\n",
      "          [-0.0245, -0.0146, -0.0152],\n",
      "          [-0.0111,  0.0436, -0.0065]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0137, -0.0354,  0.0104],\n",
      "          [ 0.0083, -0.0275,  0.0176],\n",
      "          [-0.0005, -0.0380,  0.0129]],\n",
      "\n",
      "         [[-0.0054, -0.0682,  0.0124],\n",
      "          [ 0.0213, -0.0103,  0.0022],\n",
      "          [-0.0363, -0.0297, -0.0145]],\n",
      "\n",
      "         [[ 0.0165,  0.0194, -0.0246],\n",
      "          [-0.0087,  0.0139, -0.0116],\n",
      "          [ 0.0142,  0.0073,  0.0210]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0078, -0.0158,  0.0119],\n",
      "          [ 0.0011,  0.0126,  0.0059],\n",
      "          [ 0.0050,  0.0199,  0.0072]],\n",
      "\n",
      "         [[ 0.0195,  0.0333,  0.0525],\n",
      "          [-0.0188,  0.0027,  0.0711],\n",
      "          [-0.0170, -0.0240,  0.0155]],\n",
      "\n",
      "         [[ 0.0296,  0.0029,  0.0043],\n",
      "          [ 0.0233, -0.0067,  0.0041],\n",
      "          [-0.0032,  0.0147,  0.0273]]],\n",
      "\n",
      "\n",
      "        [[[-0.0415, -0.0044, -0.0344],\n",
      "          [ 0.0193,  0.0261, -0.0254],\n",
      "          [ 0.0375,  0.0222, -0.0436]],\n",
      "\n",
      "         [[ 0.0186,  0.0063, -0.0253],\n",
      "          [-0.0016,  0.0005, -0.0379],\n",
      "          [-0.0197, -0.0363, -0.0562]],\n",
      "\n",
      "         [[-0.0012, -0.0292, -0.0177],\n",
      "          [-0.0162, -0.0023, -0.0395],\n",
      "          [ 0.0421,  0.0256,  0.0574]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0049, -0.0178,  0.0141],\n",
      "          [ 0.0065,  0.0080,  0.0175],\n",
      "          [-0.0098, -0.0040,  0.0337]],\n",
      "\n",
      "         [[ 0.0210,  0.0596,  0.0220],\n",
      "          [-0.1014, -0.0404, -0.0289],\n",
      "          [ 0.0319,  0.0404, -0.0183]],\n",
      "\n",
      "         [[-0.0340, -0.0059, -0.0411],\n",
      "          [ 0.0031,  0.0057, -0.0079],\n",
      "          [-0.0189,  0.0329,  0.0191]]],\n",
      "\n",
      "\n",
      "        [[[-0.0030, -0.0113, -0.0119],\n",
      "          [ 0.0461,  0.0017, -0.0204],\n",
      "          [ 0.0210, -0.0129, -0.0555]],\n",
      "\n",
      "         [[ 0.0038,  0.0119,  0.0223],\n",
      "          [ 0.0026, -0.0042,  0.0096],\n",
      "          [ 0.0234,  0.0130,  0.0311]],\n",
      "\n",
      "         [[ 0.0052, -0.0227, -0.0045],\n",
      "          [-0.0219, -0.0020,  0.0016],\n",
      "          [-0.0115, -0.0159, -0.0070]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0377, -0.0017, -0.0226],\n",
      "          [-0.0583, -0.0326, -0.0232],\n",
      "          [-0.0267, -0.0481, -0.0238]],\n",
      "\n",
      "         [[-0.0270, -0.0148, -0.0282],\n",
      "          [-0.0517, -0.0485, -0.0239],\n",
      "          [-0.0125, -0.0091, -0.0253]],\n",
      "\n",
      "         [[-0.0076,  0.0275,  0.0002],\n",
      "          [ 0.0231, -0.0102,  0.0005],\n",
      "          [-0.0274,  0.0054,  0.0065]]]], device='cuda:0')\n",
      "conv2.weight\n",
      "torch.Size([96, 144, 3, 3])\n",
      "tensor([[[[ 7.4627e-03,  4.5776e-03, -2.7483e-02],\n",
      "          [ 1.2417e-02, -3.0831e-02, -4.0057e-02],\n",
      "          [ 6.5995e-02,  2.8761e-03, -3.0291e-02]],\n",
      "\n",
      "         [[ 5.1432e-03,  2.3563e-02,  2.4154e-02],\n",
      "          [-3.2415e-02, -8.2433e-03,  3.0349e-02],\n",
      "          [-5.9379e-03, -6.8068e-03,  1.7782e-02]],\n",
      "\n",
      "         [[-2.8826e-03, -5.4241e-03, -1.2456e-02],\n",
      "          [-2.0999e-02,  1.6230e-02, -2.7259e-02],\n",
      "          [ 4.4926e-02,  2.4327e-02,  4.1059e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3354e-02, -1.3657e-02,  1.4022e-02],\n",
      "          [-2.6200e-02, -5.2676e-02, -2.6794e-03],\n",
      "          [ 2.4926e-02,  4.1218e-02,  2.1937e-02]],\n",
      "\n",
      "         [[-1.5879e-02, -2.4886e-02, -7.7869e-03],\n",
      "          [-3.8605e-02, -5.8857e-03,  2.1610e-02],\n",
      "          [-1.0968e-02, -2.2077e-02,  7.9214e-03]],\n",
      "\n",
      "         [[-2.9538e-03, -3.8546e-03, -3.1900e-02],\n",
      "          [ 9.1448e-04, -2.7314e-02,  1.3618e-02],\n",
      "          [-3.3429e-02,  1.8173e-03, -5.2780e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7321e-02,  3.3673e-02,  2.8678e-02],\n",
      "          [ 2.5791e-02,  2.0317e-02,  1.5320e-02],\n",
      "          [-5.5510e-03, -5.9622e-03, -1.7597e-02]],\n",
      "\n",
      "         [[-1.7336e-02, -1.5920e-02,  2.1974e-02],\n",
      "          [-1.6279e-02, -3.7197e-04,  1.4974e-02],\n",
      "          [ 5.0124e-02, -2.6288e-02, -1.8815e-02]],\n",
      "\n",
      "         [[-5.3663e-02, -4.7298e-03, -4.6932e-02],\n",
      "          [-2.3815e-02,  1.0034e-02, -3.9018e-03],\n",
      "          [-5.1001e-02,  3.2327e-02, -4.7125e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.7162e-03,  3.1915e-03,  1.7967e-02],\n",
      "          [ 9.8611e-03, -2.1725e-02, -5.2649e-03],\n",
      "          [ 1.3416e-02,  2.3309e-02,  3.1830e-02]],\n",
      "\n",
      "         [[-3.3931e-02, -7.6512e-04, -1.8836e-02],\n",
      "          [-2.6315e-02, -9.4182e-03, -2.8570e-02],\n",
      "          [-1.4241e-02,  2.3139e-02, -1.0169e-02]],\n",
      "\n",
      "         [[-3.2717e-03,  3.1322e-02, -2.9473e-02],\n",
      "          [-1.3621e-02, -1.0299e-02, -2.2866e-02],\n",
      "          [ 2.0526e-02, -9.6796e-03, -1.2572e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.2341e-03, -5.4378e-02, -4.3445e-02],\n",
      "          [ 7.7543e-03, -3.1637e-02, -2.3406e-02],\n",
      "          [-1.2142e-02, -1.6599e-02,  3.5679e-03]],\n",
      "\n",
      "         [[-2.9273e-02, -6.6784e-03,  2.9498e-02],\n",
      "          [ 1.1129e-02,  1.3927e-02, -1.3928e-02],\n",
      "          [ 8.2908e-03,  2.7698e-02,  2.7778e-02]],\n",
      "\n",
      "         [[-6.6023e-03, -3.1227e-02,  8.1534e-03],\n",
      "          [ 4.1367e-02,  2.6473e-02,  2.2769e-02],\n",
      "          [ 3.1660e-02, -1.4329e-02,  1.4363e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9846e-02, -1.5337e-02, -1.1531e-02],\n",
      "          [-1.5194e-02,  2.5697e-02,  2.2868e-02],\n",
      "          [ 1.7926e-02,  7.4837e-03, -3.7748e-02]],\n",
      "\n",
      "         [[ 3.2161e-02,  7.8171e-03,  3.2695e-02],\n",
      "          [ 7.3614e-03,  3.4029e-02, -1.2009e-02],\n",
      "          [-4.8342e-02, -3.1898e-02, -4.1270e-02]],\n",
      "\n",
      "         [[-1.2002e-02, -2.1469e-02,  3.1397e-02],\n",
      "          [ 2.4742e-02,  1.1295e-02,  3.5131e-02],\n",
      "          [-3.4364e-02,  1.5319e-03,  2.7013e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.2947e-02, -2.8069e-02,  9.6639e-03],\n",
      "          [-9.5700e-03, -9.1818e-03, -2.0946e-02],\n",
      "          [ 3.2627e-03, -1.2362e-02, -2.0920e-02]],\n",
      "\n",
      "         [[-1.8784e-02, -4.5844e-02, -2.5519e-02],\n",
      "          [-6.9731e-02, -5.1010e-02, -2.3974e-02],\n",
      "          [-6.3703e-02, -2.4460e-02,  3.7219e-04]],\n",
      "\n",
      "         [[-1.9218e-02,  2.9740e-02,  9.3693e-03],\n",
      "          [ 1.7385e-02,  4.2476e-02,  2.0878e-02],\n",
      "          [-7.7711e-03,  2.3414e-03, -6.9820e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7115e-02, -4.7412e-02, -6.5972e-03],\n",
      "          [-3.2067e-03,  1.3809e-02, -1.4366e-02],\n",
      "          [ 4.1450e-02,  2.4121e-02,  1.1400e-02]],\n",
      "\n",
      "         [[-1.5133e-03,  2.3616e-02, -1.9209e-02],\n",
      "          [-1.3377e-05,  9.0055e-03, -2.3046e-02],\n",
      "          [-2.1618e-02,  3.0836e-03,  5.4258e-03]],\n",
      "\n",
      "         [[ 4.1903e-02,  2.5183e-02,  1.3897e-02],\n",
      "          [ 2.3516e-03,  3.6260e-03,  1.0709e-02],\n",
      "          [-2.5696e-02, -3.0900e-02,  3.9530e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1804e-02, -2.3809e-04,  1.7168e-02],\n",
      "          [ 9.5721e-02,  7.6532e-02,  4.9574e-02],\n",
      "          [ 2.4022e-02,  7.3653e-03, -8.6311e-04]],\n",
      "\n",
      "         [[-1.0176e-02, -2.9854e-02, -2.6247e-03],\n",
      "          [ 3.8981e-03,  3.8876e-02,  1.0329e-02],\n",
      "          [ 2.1196e-02, -1.2127e-02, -1.5802e-02]],\n",
      "\n",
      "         [[-3.3902e-02, -2.6156e-02,  6.3882e-03],\n",
      "          [ 2.1811e-02, -2.3250e-03,  3.2791e-02],\n",
      "          [-2.1961e-02,  2.2098e-02, -1.3070e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2691e-02,  3.4936e-02,  1.1438e-02],\n",
      "          [-2.9546e-02,  2.1238e-02, -3.7392e-02],\n",
      "          [ 2.9263e-02,  1.8759e-02,  2.4611e-02]],\n",
      "\n",
      "         [[-1.8865e-02, -8.0245e-03, -1.1865e-02],\n",
      "          [ 7.7112e-04,  4.8377e-02,  1.0252e-02],\n",
      "          [-1.2943e-02,  8.8516e-03, -7.9460e-03]],\n",
      "\n",
      "         [[-3.9153e-02, -3.4979e-02, -3.2612e-02],\n",
      "          [-4.1974e-02, -1.5049e-02, -1.6711e-03],\n",
      "          [-1.9837e-02, -9.8866e-03, -2.0673e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2780e-02, -3.4600e-02, -2.9612e-02],\n",
      "          [ 3.6237e-02, -1.8125e-03,  4.7431e-02],\n",
      "          [-1.4838e-02,  6.0444e-03,  1.5574e-02]],\n",
      "\n",
      "         [[-6.0298e-02, -2.8804e-02, -4.7360e-02],\n",
      "          [ 5.0175e-02,  8.2405e-02,  3.9349e-02],\n",
      "          [-7.9768e-03,  1.2108e-02,  5.3836e-03]],\n",
      "\n",
      "         [[-3.3033e-02, -5.7143e-02, -7.5518e-02],\n",
      "          [ 6.3350e-03,  3.9815e-03,  8.3656e-03],\n",
      "          [ 2.8545e-02,  3.3149e-02,  4.7612e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1217e-02,  5.7459e-03,  3.7054e-02],\n",
      "          [-2.3455e-02, -5.7566e-02, -3.0225e-03],\n",
      "          [-8.9675e-03, -2.5513e-02,  1.6725e-02]],\n",
      "\n",
      "         [[-3.8354e-02, -2.0104e-02, -7.7344e-02],\n",
      "          [ 3.8527e-02,  8.3775e-02,  1.6144e-02],\n",
      "          [ 7.8738e-03,  3.8979e-02, -4.6116e-02]],\n",
      "\n",
      "         [[-4.4362e-02, -1.6447e-02, -3.6310e-02],\n",
      "          [-1.4617e-02,  1.3816e-02,  6.6410e-04],\n",
      "          [ 1.8814e-02, -2.0023e-02,  1.2543e-02]]]], device='cuda:0')\n",
      "conv3.weight\n",
      "torch.Size([96, 96, 3, 3])\n",
      "tensor([[[[-0.0275,  0.0246,  0.0270],\n",
      "          [-0.0563, -0.0201, -0.0608],\n",
      "          [-0.0454, -0.0509,  0.0062]],\n",
      "\n",
      "         [[ 0.0130, -0.0425,  0.0689],\n",
      "          [-0.0017, -0.0059,  0.0679],\n",
      "          [ 0.0082, -0.0266,  0.0192]],\n",
      "\n",
      "         [[-0.0235,  0.0356, -0.0196],\n",
      "          [ 0.0135,  0.0800,  0.0437],\n",
      "          [-0.0160,  0.0135, -0.0086]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0225, -0.0207,  0.0165],\n",
      "          [-0.0274,  0.0479,  0.0273],\n",
      "          [-0.0126, -0.0337,  0.0251]],\n",
      "\n",
      "         [[ 0.0279, -0.0113,  0.0073],\n",
      "          [ 0.0266,  0.0447,  0.0101],\n",
      "          [-0.0135,  0.0247,  0.0354]],\n",
      "\n",
      "         [[-0.0076, -0.0123,  0.0068],\n",
      "          [ 0.0280,  0.0364, -0.0505],\n",
      "          [-0.0324, -0.0172,  0.0020]]],\n",
      "\n",
      "\n",
      "        [[[-0.0210, -0.0399, -0.0014],\n",
      "          [ 0.0111,  0.0405,  0.0650],\n",
      "          [ 0.0185,  0.0440,  0.0510]],\n",
      "\n",
      "         [[-0.0076, -0.0366,  0.0299],\n",
      "          [ 0.0604, -0.0424,  0.0494],\n",
      "          [ 0.0630, -0.0023,  0.0266]],\n",
      "\n",
      "         [[ 0.0194,  0.0252,  0.0066],\n",
      "          [-0.0285, -0.0438, -0.0083],\n",
      "          [ 0.0205, -0.0350,  0.0149]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0280, -0.0038,  0.0147],\n",
      "          [-0.0069,  0.0011,  0.0035],\n",
      "          [-0.0120,  0.0088,  0.0057]],\n",
      "\n",
      "         [[ 0.0172,  0.0129, -0.0354],\n",
      "          [-0.0729, -0.0628, -0.0295],\n",
      "          [-0.0329, -0.0252, -0.0192]],\n",
      "\n",
      "         [[ 0.0042,  0.0203,  0.0254],\n",
      "          [-0.0451, -0.0077, -0.0243],\n",
      "          [ 0.0339,  0.0438,  0.0063]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0319, -0.0454, -0.0358],\n",
      "          [-0.0236, -0.0321,  0.0018],\n",
      "          [ 0.0489, -0.0090,  0.0446]],\n",
      "\n",
      "         [[-0.0021,  0.0101,  0.0104],\n",
      "          [ 0.0331, -0.0324, -0.0076],\n",
      "          [-0.0099, -0.0137, -0.0124]],\n",
      "\n",
      "         [[-0.0419, -0.0218, -0.0272],\n",
      "          [-0.0428, -0.0723, -0.1130],\n",
      "          [ 0.0012, -0.0206, -0.0076]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0189, -0.0504, -0.0169],\n",
      "          [-0.0299, -0.0632, -0.0405],\n",
      "          [-0.0330, -0.0217,  0.0075]],\n",
      "\n",
      "         [[ 0.0183,  0.0217,  0.0477],\n",
      "          [ 0.0628,  0.0468,  0.0373],\n",
      "          [-0.0030, -0.0135,  0.0148]],\n",
      "\n",
      "         [[-0.0008,  0.0138,  0.0141],\n",
      "          [ 0.0387,  0.0041,  0.0190],\n",
      "          [ 0.0454,  0.0155,  0.0310]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0007,  0.0236,  0.0211],\n",
      "          [ 0.0177, -0.0280, -0.0186],\n",
      "          [-0.0140,  0.0286, -0.0202]],\n",
      "\n",
      "         [[ 0.0205,  0.0486, -0.0280],\n",
      "          [ 0.0285,  0.0493, -0.0411],\n",
      "          [-0.0456,  0.0173, -0.0582]],\n",
      "\n",
      "         [[-0.0391, -0.0156,  0.0475],\n",
      "          [ 0.0196,  0.0118,  0.0145],\n",
      "          [ 0.0180, -0.0289,  0.0539]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0230,  0.0174,  0.0220],\n",
      "          [-0.0009,  0.0183, -0.0294],\n",
      "          [-0.0431, -0.0135, -0.0711]],\n",
      "\n",
      "         [[-0.0353,  0.0183,  0.0229],\n",
      "          [-0.0008,  0.0186,  0.0329],\n",
      "          [-0.0254, -0.0132,  0.0121]],\n",
      "\n",
      "         [[-0.0302,  0.0102,  0.0002],\n",
      "          [ 0.0067,  0.0155,  0.0481],\n",
      "          [ 0.0255,  0.0235,  0.0315]]],\n",
      "\n",
      "\n",
      "        [[[-0.0300,  0.0039, -0.0170],\n",
      "          [-0.0461,  0.0220,  0.0226],\n",
      "          [-0.0429, -0.0070, -0.0455]],\n",
      "\n",
      "         [[-0.0260,  0.0620, -0.0100],\n",
      "          [-0.0022,  0.0294,  0.0247],\n",
      "          [-0.0335, -0.0122, -0.0570]],\n",
      "\n",
      "         [[-0.0157,  0.0165,  0.0438],\n",
      "          [-0.0248,  0.0011,  0.1184],\n",
      "          [ 0.0076,  0.0098,  0.0341]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0261,  0.0103,  0.0299],\n",
      "          [-0.0042,  0.0449,  0.0165],\n",
      "          [-0.0187,  0.0213,  0.0104]],\n",
      "\n",
      "         [[-0.0523, -0.0706, -0.0283],\n",
      "          [-0.0263, -0.0372, -0.0385],\n",
      "          [-0.0263, -0.0076,  0.0147]],\n",
      "\n",
      "         [[-0.0140, -0.0140,  0.0098],\n",
      "          [ 0.0181, -0.0258, -0.0017],\n",
      "          [ 0.0223, -0.0362, -0.0382]]],\n",
      "\n",
      "\n",
      "        [[[-0.0619, -0.0655, -0.0461],\n",
      "          [-0.0322, -0.0434, -0.0025],\n",
      "          [ 0.0100, -0.0112,  0.0097]],\n",
      "\n",
      "         [[-0.0746,  0.0034,  0.0225],\n",
      "          [ 0.0195,  0.0287, -0.0067],\n",
      "          [-0.0662,  0.0187,  0.0014]],\n",
      "\n",
      "         [[ 0.0839,  0.0097,  0.0375],\n",
      "          [ 0.0241, -0.0227, -0.0352],\n",
      "          [-0.0234,  0.0224,  0.0141]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0089,  0.0087,  0.0602],\n",
      "          [ 0.0384, -0.0058,  0.0138],\n",
      "          [-0.0391, -0.0422, -0.0161]],\n",
      "\n",
      "         [[-0.0035,  0.0128,  0.0105],\n",
      "          [-0.0375, -0.0342, -0.0362],\n",
      "          [-0.0253, -0.0291,  0.0202]],\n",
      "\n",
      "         [[ 0.0507,  0.0113, -0.0058],\n",
      "          [-0.0246,  0.0091,  0.0138],\n",
      "          [-0.0282, -0.0172,  0.0174]]]], device='cuda:0')\n",
      "conv4.weight\n",
      "torch.Size([96, 96, 3, 3])\n",
      "tensor([[[[ 6.1541e-03, -4.4201e-02, -4.8813e-02],\n",
      "          [ 1.3678e-02, -2.9889e-02, -1.6453e-02],\n",
      "          [-1.4886e-02, -1.0702e-02, -2.2064e-02]],\n",
      "\n",
      "         [[-6.0653e-03,  5.9792e-04,  3.1024e-02],\n",
      "          [-2.6888e-02,  2.5894e-02,  1.7422e-02],\n",
      "          [ 1.4430e-02,  2.3921e-02,  2.5381e-02]],\n",
      "\n",
      "         [[ 1.3744e-02,  5.5138e-02,  5.4237e-02],\n",
      "          [ 8.7835e-03,  2.4938e-02,  9.2848e-03],\n",
      "          [ 2.0780e-03,  5.3842e-02,  1.9868e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7474e-02, -9.9097e-03,  3.5063e-02],\n",
      "          [-2.9891e-02, -1.7829e-02, -2.6489e-02],\n",
      "          [-9.3109e-03, -3.8447e-02,  1.2270e-03]],\n",
      "\n",
      "         [[-2.7328e-02, -2.0855e-03,  7.2219e-04],\n",
      "          [-3.9721e-02, -4.0958e-02, -1.4304e-02],\n",
      "          [-4.6077e-02, -5.8301e-02, -5.0795e-02]],\n",
      "\n",
      "         [[-2.0691e-03, -1.7269e-02,  2.9302e-02],\n",
      "          [-1.3395e-02,  6.0113e-03,  2.4885e-03],\n",
      "          [ 2.2956e-03, -4.4875e-02, -8.1733e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1961e-02,  7.3897e-03, -1.8556e-02],\n",
      "          [ 7.9618e-03,  2.4753e-02,  2.7996e-02],\n",
      "          [-6.2415e-03,  2.1254e-02,  6.1194e-02]],\n",
      "\n",
      "         [[ 4.4695e-02,  1.9217e-03,  1.5393e-02],\n",
      "          [ 4.6890e-02, -1.0990e-02, -1.2723e-03],\n",
      "          [ 5.8032e-02,  2.4055e-02, -4.5189e-02]],\n",
      "\n",
      "         [[-6.0820e-02, -2.7069e-02, -1.5849e-02],\n",
      "          [-3.0252e-02, -7.6918e-02,  6.7343e-03],\n",
      "          [-1.0256e-02, -6.1555e-02, -1.2614e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0642e-02, -1.3219e-02,  1.3816e-02],\n",
      "          [ 1.6293e-02,  5.2656e-02,  1.5129e-03],\n",
      "          [ 5.0457e-02,  6.4006e-02, -6.1006e-03]],\n",
      "\n",
      "         [[ 4.3323e-02, -2.4039e-03,  1.2682e-02],\n",
      "          [ 5.5453e-02,  4.7908e-02, -4.7316e-03],\n",
      "          [-1.2379e-02,  6.4870e-02,  2.4931e-02]],\n",
      "\n",
      "         [[-5.5333e-03, -1.2766e-02, -1.0453e-02],\n",
      "          [ 3.7380e-02,  4.8915e-02,  1.9973e-02],\n",
      "          [-3.1160e-02, -2.4487e-02,  2.9735e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4456e-02, -3.6492e-02,  9.5026e-03],\n",
      "          [-4.1485e-02, -3.8844e-02, -1.5137e-02],\n",
      "          [-2.0871e-02,  1.2588e-02,  1.2887e-02]],\n",
      "\n",
      "         [[ 2.0036e-02,  1.2234e-03, -2.1596e-02],\n",
      "          [ 6.3747e-02, -7.2532e-03, -1.4183e-02],\n",
      "          [ 4.4692e-03, -9.5346e-03, -2.8106e-02]],\n",
      "\n",
      "         [[ 4.7117e-03, -2.1796e-02,  2.9782e-02],\n",
      "          [-6.0853e-02, -1.8416e-02, -4.8931e-02],\n",
      "          [-3.6890e-02, -1.0473e-02, -4.7223e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1420e-02, -1.5784e-02, -3.1242e-02],\n",
      "          [ 1.4913e-02, -2.5773e-02, -5.9857e-02],\n",
      "          [-6.0901e-03, -3.7089e-02, -5.1078e-02]],\n",
      "\n",
      "         [[ 3.1030e-02, -5.9838e-03,  2.8098e-02],\n",
      "          [ 2.4233e-02,  2.7887e-02, -3.9169e-03],\n",
      "          [ 4.3739e-02, -1.3050e-02,  3.8583e-02]],\n",
      "\n",
      "         [[ 4.3861e-02,  8.8330e-03,  4.4843e-03],\n",
      "          [-4.1709e-03,  3.8197e-03,  2.2356e-02],\n",
      "          [ 6.4829e-04,  2.4782e-02,  6.2732e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.6182e-02, -2.8433e-02, -4.9078e-02],\n",
      "          [ 3.9576e-02,  3.1661e-02,  9.4121e-03],\n",
      "          [ 1.3546e-02, -4.1846e-02, -1.2876e-02]],\n",
      "\n",
      "         [[-3.4085e-02, -1.5001e-02,  4.0700e-02],\n",
      "          [-8.0954e-02,  1.6355e-02, -2.4416e-02],\n",
      "          [ 1.9648e-02,  1.2417e-02, -8.1213e-03]],\n",
      "\n",
      "         [[-6.1114e-03, -2.0618e-03,  1.2169e-02],\n",
      "          [ 1.3514e-02,  5.2285e-02, -3.3979e-03],\n",
      "          [ 6.7240e-02, -4.8322e-03, -2.5707e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.7589e-03,  3.9008e-02,  3.8425e-03],\n",
      "          [-1.6744e-02,  3.3897e-02,  2.0550e-03],\n",
      "          [-4.1346e-02, -4.1652e-02, -2.2638e-02]],\n",
      "\n",
      "         [[ 3.6150e-02, -2.6899e-02, -2.8112e-02],\n",
      "          [-8.5666e-03, -6.0163e-02, -5.3736e-03],\n",
      "          [ 2.2485e-02,  2.6868e-03, -2.4429e-02]],\n",
      "\n",
      "         [[-1.4578e-03,  9.6746e-03,  1.0022e-02],\n",
      "          [ 5.0596e-04, -2.4977e-02, -2.7798e-02],\n",
      "          [ 2.7424e-02, -1.0754e-02, -5.5728e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4252e-02,  2.3934e-02,  4.0199e-02],\n",
      "          [-5.5749e-02, -4.7966e-02,  6.5711e-03],\n",
      "          [-1.6459e-02, -6.5347e-03, -6.1708e-05]],\n",
      "\n",
      "         [[ 7.7750e-03,  1.2412e-02, -2.7014e-03],\n",
      "          [ 2.4548e-02,  2.7289e-02, -2.4700e-02],\n",
      "          [-2.8208e-03, -1.3840e-02, -3.5995e-02]],\n",
      "\n",
      "         [[ 2.5229e-02, -1.2298e-02, -7.3292e-03],\n",
      "          [ 5.2233e-03, -2.7916e-02,  1.0863e-02],\n",
      "          [-2.6716e-02, -1.9724e-02, -1.8220e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4562e-02,  5.6639e-03, -4.2280e-02],\n",
      "          [ 2.8386e-02,  2.6106e-02, -2.5449e-02],\n",
      "          [-1.9988e-02,  8.7227e-03,  3.0471e-02]],\n",
      "\n",
      "         [[ 1.1185e-02,  7.3397e-03, -2.8680e-02],\n",
      "          [-2.8747e-02,  1.4243e-02,  3.0204e-02],\n",
      "          [-2.4839e-02, -2.0416e-02, -1.7196e-02]],\n",
      "\n",
      "         [[ 3.5533e-02,  6.0157e-02, -7.0684e-04],\n",
      "          [-2.2595e-03,  3.1443e-02,  3.6567e-02],\n",
      "          [-4.3062e-02, -4.6291e-02, -4.6273e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6300e-02,  3.3529e-02,  2.6482e-02],\n",
      "          [ 7.3799e-04,  1.7403e-02,  5.5459e-02],\n",
      "          [-1.6957e-02, -1.1560e-02,  1.8460e-02]],\n",
      "\n",
      "         [[-1.5185e-02, -1.0384e-02, -1.8787e-02],\n",
      "          [ 5.7502e-02,  8.7692e-03, -5.2449e-03],\n",
      "          [-1.1324e-02, -1.5740e-03,  1.1369e-02]],\n",
      "\n",
      "         [[-6.3531e-02, -8.6117e-02, -2.4729e-02],\n",
      "          [ 8.4919e-03, -9.8860e-03,  2.2231e-02],\n",
      "          [-3.4034e-02, -1.9178e-02,  1.7686e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0785e-02, -2.6871e-02, -3.6998e-02],\n",
      "          [ 4.5864e-02,  4.7240e-03, -1.7630e-02],\n",
      "          [ 2.8650e-02,  2.3311e-02,  2.7738e-03]],\n",
      "\n",
      "         [[ 1.1569e-02, -6.9855e-03,  2.9620e-02],\n",
      "          [-5.9728e-03,  2.5752e-02,  6.9128e-03],\n",
      "          [ 3.0600e-02, -1.6364e-02,  2.1874e-02]],\n",
      "\n",
      "         [[-2.2572e-02, -2.0052e-02, -1.4124e-02],\n",
      "          [ 4.3293e-02,  4.2569e-02,  5.6088e-02],\n",
      "          [-4.6164e-02, -5.5484e-02, -3.8047e-02]]]], device='cuda:0')\n",
      "reghead.bias\n",
      "torch.Size([2])\n",
      "tensor([-0.0079,  0.0233], device='cuda:0')\n",
      "reghead.weight\n",
      "torch.Size([2, 96, 3, 3])\n",
      "tensor([[[[ 0.0166, -0.0118,  0.0185],\n",
      "          [ 0.0168, -0.0038, -0.0142],\n",
      "          [-0.0179, -0.0132, -0.0144]],\n",
      "\n",
      "         [[ 0.0138, -0.0340,  0.0123],\n",
      "          [-0.0212, -0.0067,  0.0134],\n",
      "          [ 0.0065,  0.0083,  0.0184]],\n",
      "\n",
      "         [[-0.0086, -0.0208, -0.0376],\n",
      "          [-0.0116, -0.0239, -0.0125],\n",
      "          [ 0.0543,  0.0203,  0.0550]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0173, -0.0072,  0.0039],\n",
      "          [ 0.0340,  0.0298,  0.0157],\n",
      "          [-0.0318, -0.0192, -0.0413]],\n",
      "\n",
      "         [[-0.0179, -0.0101, -0.0048],\n",
      "          [ 0.0118, -0.0149,  0.0163],\n",
      "          [ 0.0013,  0.0126, -0.0041]],\n",
      "\n",
      "         [[-0.0005, -0.0128, -0.0127],\n",
      "          [ 0.0132,  0.0224,  0.0034],\n",
      "          [-0.0128, -0.0106,  0.0012]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0504, -0.0134, -0.0554],\n",
      "          [ 0.0019,  0.0261, -0.0334],\n",
      "          [ 0.0090, -0.0198, -0.0022]],\n",
      "\n",
      "         [[-0.0631,  0.0258,  0.0255],\n",
      "          [-0.0145,  0.0158,  0.0270],\n",
      "          [-0.0447, -0.0173,  0.0379]],\n",
      "\n",
      "         [[-0.0077, -0.0282,  0.0175],\n",
      "          [-0.0291,  0.0115,  0.0173],\n",
      "          [ 0.0034, -0.0152, -0.0161]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0159,  0.0088,  0.0012],\n",
      "          [ 0.0127,  0.0082, -0.0277],\n",
      "          [ 0.0001, -0.0199,  0.0043]],\n",
      "\n",
      "         [[-0.0176, -0.0036,  0.0246],\n",
      "          [ 0.0153, -0.0035, -0.0193],\n",
      "          [ 0.0039,  0.0149, -0.0169]],\n",
      "\n",
      "         [[-0.0254, -0.0206,  0.0246],\n",
      "          [-0.0185,  0.0226,  0.0259],\n",
      "          [-0.0357,  0.0103,  0.0015]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# get the keys:\n",
    "# q = model.state_dict()\n",
    "# print(q.keys())\n",
    "\n",
    "# copy part of FFTRadNet model - DH_model - detection header\n",
    "DH_model = model.detection_header\n",
    "DH_model_dict = model.detection_header.state_dict()\n",
    "for key in sorted(DH_model_dict.keys()):\n",
    "    parameter = DH_model_dict[key]\n",
    "    print(key)\n",
    "    print(parameter.size())\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xm0523/.local/lib/python3.9/site-packages/torch/ao/quantization/observer.py:1204: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Quantize DH_model:\n",
    "\n",
    "# Post-training Static Quantization.\n",
    "# Let's try without fusion:\n",
    "DH_model.to('cpu')\n",
    "backend = \"qnnpack\"\n",
    "DH_model.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "torch.backends.quantized.engine = backend\n",
    "model_static_quantized = torch.quantization.prepare(DH_model, inplace=False)\n",
    "model_static_quantized = torch.quantization.convert(model_static_quantized, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection_Header(\n",
      "  (conv1): QuantizedConv2d(256, 144, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
      "  (bn1): QuantizedBatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): QuantizedConv2d(144, 96, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
      "  (bn2): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): QuantizedConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
      "  (bn3): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): QuantizedConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
      "  (bn4): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (clshead): QuantizedConv2d(96, 1, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
      "  (reghead): QuantizedConv2d(96, 2, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_static_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 18,  16,  -1],\n",
      "          [ 11, -11,  10],\n",
      "          [-13,  -9, -17]],\n",
      "\n",
      "         [[-14,  30, -18],\n",
      "          [  7,  10,   2],\n",
      "          [  9,  41,  19]],\n",
      "\n",
      "         [[ -5, -12,   6],\n",
      "          [ -1,   1,  12],\n",
      "          [ 10,  24,  -9]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 32,  15,  16],\n",
      "          [ 14,  43,  15],\n",
      "          [ 34,  14,  15]],\n",
      "\n",
      "         [[ 39,   3,  29],\n",
      "          [-25, -20,   3],\n",
      "          [ 14,  19,  14]],\n",
      "\n",
      "         [[-35, -13, -21],\n",
      "          [ -4, -11,  -6],\n",
      "          [ 13,   6,  -9]]],\n",
      "\n",
      "\n",
      "        [[[ 22,  28,  42],\n",
      "          [ -4,  17,  47],\n",
      "          [ 31,  -3,  17]],\n",
      "\n",
      "         [[-17, -51, -35],\n",
      "          [-16, -46, -22],\n",
      "          [-29, -38,  -2]],\n",
      "\n",
      "         [[-15,   9,   4],\n",
      "          [ 14,  10, -13],\n",
      "          [-27, -15, -23]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-20, -35,   5],\n",
      "          [-40, -42,  -4],\n",
      "          [-17, -42,   1]],\n",
      "\n",
      "         [[ 14,  34,   3],\n",
      "          [-19, -12, -23],\n",
      "          [-15,   8,  -4]],\n",
      "\n",
      "         [[ 16,  13,  12],\n",
      "          [ 15,  19,   1],\n",
      "          [ -7,  -5, -14]]],\n",
      "\n",
      "\n",
      "        [[[ -3,   6, -23],\n",
      "          [ -2,  16,  -6],\n",
      "          [-25,  -6, -21]],\n",
      "\n",
      "         [[ 19,  29, -16],\n",
      "          [ 27,  -1, -33],\n",
      "          [ 20,  18, -11]],\n",
      "\n",
      "         [[-16, -13,  -4],\n",
      "          [-12,   2,  -2],\n",
      "          [ 18,  30,  14]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  9,  13,  16],\n",
      "          [ 23,  26,  26],\n",
      "          [ 17,   9,  -6]],\n",
      "\n",
      "         [[ 44,  12,  24],\n",
      "          [-30, -36, -16],\n",
      "          [  8,  11,  -5]],\n",
      "\n",
      "         [[-27, -17, -27],\n",
      "          [-19, -11, -12],\n",
      "          [ -9,  34,  -5]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 11, -28,   8],\n",
      "          [  7, -22,  14],\n",
      "          [  0, -30,  10]],\n",
      "\n",
      "         [[ -4, -54,  10],\n",
      "          [ 17,  -8,   2],\n",
      "          [-28, -23, -11]],\n",
      "\n",
      "         [[ 13,  15, -19],\n",
      "          [ -7,  11,  -9],\n",
      "          [ 11,   6,  17]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ -6, -12,   9],\n",
      "          [  1,  10,   5],\n",
      "          [  4,  16,   6]],\n",
      "\n",
      "         [[ 15,  26,  41],\n",
      "          [-15,   2,  56],\n",
      "          [-13, -19,  12]],\n",
      "\n",
      "         [[ 23,   2,   3],\n",
      "          [ 18,  -5,   3],\n",
      "          [ -3,  12,  21]]],\n",
      "\n",
      "\n",
      "        [[[-33,  -3, -27],\n",
      "          [ 15,  20, -20],\n",
      "          [ 29,  17, -34]],\n",
      "\n",
      "         [[ 15,   5, -20],\n",
      "          [ -1,   0, -30],\n",
      "          [-15, -29, -44]],\n",
      "\n",
      "         [[ -1, -23, -14],\n",
      "          [-13,  -2, -31],\n",
      "          [ 33,  20,  45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  4, -14,  11],\n",
      "          [  5,   6,  14],\n",
      "          [ -8,  -3,  26]],\n",
      "\n",
      "         [[ 16,  47,  17],\n",
      "          [-80, -32, -23],\n",
      "          [ 25,  32, -14]],\n",
      "\n",
      "         [[-27,  -5, -32],\n",
      "          [  2,   4,  -6],\n",
      "          [-15,  26,  15]]],\n",
      "\n",
      "\n",
      "        [[[ -2,  -9,  -9],\n",
      "          [ 36,   1, -16],\n",
      "          [ 16, -10, -44]],\n",
      "\n",
      "         [[  3,   9,  17],\n",
      "          [  2,  -3,   8],\n",
      "          [ 18,  10,  24]],\n",
      "\n",
      "         [[  4, -18,  -4],\n",
      "          [-17,  -2,   1],\n",
      "          [ -9, -12,  -6]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-30,  -1, -18],\n",
      "          [-46, -26, -18],\n",
      "          [-21, -38, -19]],\n",
      "\n",
      "         [[-21, -12, -22],\n",
      "          [-41, -38, -19],\n",
      "          [-10,  -7, -20]],\n",
      "\n",
      "         [[ -6,  22,   0],\n",
      "          [ 18,  -8,   0],\n",
      "          [-21,   4,   5]]]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "# Weights from non-fusion model:\n",
    "print(model_static_quantized.conv1.weight().int_repr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantize DH_model:\n",
    "\n",
    "# Static quantization of a model consists of the following steps:\n",
    "#     Fuse modules\n",
    "#     Insert Quant/DeQuant Stubs\n",
    "#     Prepare the fused module (insert observers before and after layers)\n",
    "#     Calibrate the prepared module (pass it representative data)\n",
    "#     Convert the calibrated module (replace with quantized version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Detection_Header(\n",
       "  (conv1): Conv2d(256, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(144, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (clshead): Conv2d(96, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (reghead): Conv2d(96, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "from torch import nn\n",
    "\n",
    "DH_m = copy.deepcopy(DH_model)\n",
    "DH_m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quantized(nn.Module):\n",
    "    def __init__(self, model_fp32):\n",
    "        super(Quantized, self).__init__()\n",
    "        # QuantStub converts tensors from floating point to quantized.\n",
    "        # This will only be used for inputs.\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        # FP32 model\n",
    "        self.model_fp32 = model_fp32\n",
    "        # DeQuantStub converts tensors from quantized to floating point.\n",
    "        # This will only be used for outputs.\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # manually specify where tensors will be converted from floating\n",
    "        # point to quantized in the quantized model\n",
    "        x = self.quant(x)\n",
    "        x = self.model_fp32(x)\n",
    "        # manually specify where tensors will be converted from quantized\n",
    "        # to floating point in the quantized model\n",
    "        x = self.dequant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xm0523/.local/lib/python3.9/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Fuse\n",
    "- Inplace fusion replaces the first module in the sequence with the fused module, and the rest with identity modules\n",
    "\"\"\"\n",
    "torch.quantization.fuse_modules(DH_m, ['conv1','bn1'], inplace=True) # fuse first Conv-BatchNorm pair\n",
    "torch.quantization.fuse_modules(DH_m, ['conv2','bn2'], inplace=True) # fuse second Conv-BatchNorm pair\n",
    "torch.quantization.fuse_modules(DH_m, ['conv3','bn3'], inplace=True) # fuse third Conv-BatchNorm pair\n",
    "torch.quantization.fuse_modules(DH_m, ['conv4','bn4'], inplace=True) # fuse fourth Conv-BatchNorm pair\n",
    "\n",
    "\"\"\"Insert stubs\"\"\"\n",
    "quantized_model = Quantized(model_fp32=DH_m)\n",
    "\n",
    "\"\"\"Prepare\"\"\"\n",
    "# DH_m.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "quantized_model.qconfig = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
    "    \n",
    "# Print quantization configurations\n",
    "print(quantized_model.qconfig)\n",
    "\n",
    "DH_m_prepared = torch.quantization.prepare(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the prepared model to determine quantization parameters for activations\n",
    "# in a real world setting, the calibration would be done with a representative dataset\n",
    "input_fp32 = torch.randn(144, 256, 3, 3)\n",
    "DH_m_prepared(input_fp32)\n",
    "\n",
    "# Convert the observed model to a quantized model. This does several things:\n",
    "# quantizes the weights, computes and stores the scale and bias value to be\n",
    "# used with each activation tensor, and replaces key operators with quantized\n",
    "# implementations.\n",
    "DH_m_int8 = torch.quantization.convert(DH_m_prepared)\n",
    "\n",
    "DH_m_int8.eval()\n",
    "# run the model, relevant calculations will happen in int8\n",
    "res_int8 = DH_m_int8(input_fp32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized(\n",
      "  (quant): QuantStub(\n",
      "    (activation_post_process): HistogramObserver(min_val=-4.521451473236084, max_val=4.27418327331543)\n",
      "  )\n",
      "  (model_fp32): Detection_Header(\n",
      "    (conv1): Conv2d(\n",
      "      256, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (activation_post_process): HistogramObserver(min_val=-5.190605163574219, max_val=4.576180458068848)\n",
      "    )\n",
      "    (bn1): Identity()\n",
      "    (conv2): Conv2d(\n",
      "      144, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (activation_post_process): HistogramObserver(min_val=-3.0808920860290527, max_val=3.477532386779785)\n",
      "    )\n",
      "    (bn2): Identity()\n",
      "    (conv3): Conv2d(\n",
      "      96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (activation_post_process): HistogramObserver(min_val=-2.301859140396118, max_val=2.0950284004211426)\n",
      "    )\n",
      "    (bn3): Identity()\n",
      "    (conv4): Conv2d(\n",
      "      96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (activation_post_process): HistogramObserver(min_val=-1.3431458473205566, max_val=1.4078645706176758)\n",
      "    )\n",
      "    (bn4): Identity()\n",
      "    (clshead): Conv2d(\n",
      "      96, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (activation_post_process): HistogramObserver(min_val=-18.546714782714844, max_val=2.0191612243652344)\n",
      "    )\n",
      "    (reghead): Conv2d(\n",
      "      96, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (activation_post_process): HistogramObserver(min_val=-0.7518197298049927, max_val=0.7303507328033447)\n",
      "    )\n",
      "  )\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "tensor([[[[  4,   4,   0],\n",
      "          [  3,  -3,   2],\n",
      "          [ -3,  -2,  -4]],\n",
      "\n",
      "         [[ -4,   7,  -4],\n",
      "          [  2,   2,   0],\n",
      "          [  2,  10,   5]],\n",
      "\n",
      "         [[ -1,  -3,   1],\n",
      "          [  0,   0,   3],\n",
      "          [  2,   6,  -2]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  8,   4,   4],\n",
      "          [  4,  11,   4],\n",
      "          [  8,   3,   4]],\n",
      "\n",
      "         [[ 10,   1,   7],\n",
      "          [ -6,  -5,   1],\n",
      "          [  3,   5,   4]],\n",
      "\n",
      "         [[ -9,  -3,  -5],\n",
      "          [ -1,  -3,  -1],\n",
      "          [  3,   2,  -2]]],\n",
      "\n",
      "\n",
      "        [[[  5,   7,  10],\n",
      "          [ -1,   4,  11],\n",
      "          [  7,  -1,   4]],\n",
      "\n",
      "         [[ -4, -12,  -8],\n",
      "          [ -4, -11,  -5],\n",
      "          [ -7,  -9,   0]],\n",
      "\n",
      "         [[ -4,   2,   1],\n",
      "          [  3,   2,  -3],\n",
      "          [ -6,  -3,  -6]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ -5,  -8,   1],\n",
      "          [-10, -10,  -1],\n",
      "          [ -4, -10,   0]],\n",
      "\n",
      "         [[  3,   8,   1],\n",
      "          [ -5,  -3,  -6],\n",
      "          [ -3,   2,  -1]],\n",
      "\n",
      "         [[  4,   3,   3],\n",
      "          [  4,   4,   0],\n",
      "          [ -2,  -1,  -3]]],\n",
      "\n",
      "\n",
      "        [[[ -1,   1,  -4],\n",
      "          [  0,   3,  -1],\n",
      "          [ -4,  -1,  -3]],\n",
      "\n",
      "         [[  3,   5,  -3],\n",
      "          [  4,   0,  -5],\n",
      "          [  3,   3,  -2]],\n",
      "\n",
      "         [[ -3,  -2,  -1],\n",
      "          [ -2,   0,   0],\n",
      "          [  3,   5,   2]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  1,   2,   3],\n",
      "          [  4,   4,   4],\n",
      "          [  3,   1,  -1]],\n",
      "\n",
      "         [[  7,   2,   4],\n",
      "          [ -5,  -6,  -3],\n",
      "          [  1,   2,  -1]],\n",
      "\n",
      "         [[ -4,  -3,  -4],\n",
      "          [ -3,  -2,  -2],\n",
      "          [ -1,   5,  -1]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[  6, -16,   5],\n",
      "          [  4, -12,   8],\n",
      "          [  0, -17,   6]],\n",
      "\n",
      "         [[ -2, -31,   6],\n",
      "          [ 10,  -5,   1],\n",
      "          [-16, -13,  -7]],\n",
      "\n",
      "         [[  7,   9, -11],\n",
      "          [ -4,   6,  -5],\n",
      "          [  6,   3,  10]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ -4,  -7,   5],\n",
      "          [  1,   6,   3],\n",
      "          [  2,   9,   3]],\n",
      "\n",
      "         [[  9,  15,  24],\n",
      "          [ -8,   1,  32],\n",
      "          [ -8, -11,   7]],\n",
      "\n",
      "         [[ 13,   1,   2],\n",
      "          [ 11,  -3,   2],\n",
      "          [ -1,   7,  12]]],\n",
      "\n",
      "\n",
      "        [[[-10,  -1,  -8],\n",
      "          [  5,   6,  -6],\n",
      "          [  9,   5, -11]],\n",
      "\n",
      "         [[  4,   2,  -6],\n",
      "          [  0,   0,  -9],\n",
      "          [ -5,  -9, -14]],\n",
      "\n",
      "         [[  0,  -7,  -4],\n",
      "          [ -4,  -1, -10],\n",
      "          [ 10,   6,  14]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  1,  -4,   3],\n",
      "          [  2,   2,   4],\n",
      "          [ -2,  -1,   8]],\n",
      "\n",
      "         [[  5,  14,   5],\n",
      "          [-24, -10,  -7],\n",
      "          [  8,  10,  -4]],\n",
      "\n",
      "         [[ -8,  -1, -10],\n",
      "          [  1,   1,  -2],\n",
      "          [ -5,   8,   5]]],\n",
      "\n",
      "\n",
      "        [[[ -1,  -3,  -3],\n",
      "          [ 13,   0,  -6],\n",
      "          [  6,  -4, -15]],\n",
      "\n",
      "         [[  1,   3,   6],\n",
      "          [  1,  -1,   3],\n",
      "          [  6,   4,   9]],\n",
      "\n",
      "         [[  1,  -6,  -1],\n",
      "          [ -6,  -1,   0],\n",
      "          [ -3,  -4,  -2]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-10,   0,  -6],\n",
      "          [-16,  -9,  -6],\n",
      "          [ -7, -13,  -7]],\n",
      "\n",
      "         [[ -7,  -4,  -8],\n",
      "          [-14, -13,  -7],\n",
      "          [ -3,  -2,  -7]],\n",
      "\n",
      "         [[ -2,   8,   0],\n",
      "          [  6,  -3,   0],\n",
      "          [ -7,   1,   2]]]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "print(DH_m_prepared)\n",
    "#print(DH_m_int8.model_fp32.conv1.weight()) # float but has output scale and zero_factor\n",
    "print(DH_m_int8.model_fp32.conv1.weight().int_repr()) # output result in int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized(\n",
      "  (quant): Quantize(scale=tensor([0.0647]), zero_point=tensor([66]), dtype=torch.quint8)\n",
      "  (model_fp32): Detection_Header(\n",
      "    (conv1): QuantizedConv2d(256, 144, kernel_size=(3, 3), stride=(1, 1), scale=0.033345166593790054, zero_point=129, padding=(1, 1))\n",
      "    (bn1): Identity()\n",
      "    (conv2): QuantizedConv2d(144, 96, kernel_size=(3, 3), stride=(1, 1), scale=0.022014625370502472, zero_point=115, padding=(1, 1))\n",
      "    (bn2): Identity()\n",
      "    (conv3): QuantizedConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), scale=0.01560093741863966, zero_point=136, padding=(1, 1))\n",
      "    (bn3): Identity()\n",
      "    (conv4): QuantizedConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), scale=0.010387929156422615, zero_point=125, padding=(1, 1))\n",
      "    (bn4): Identity()\n",
      "    (clshead): QuantizedConv2d(96, 1, kernel_size=(3, 3), stride=(1, 1), scale=0.08049296587705612, zero_point=230, padding=(1, 1))\n",
      "    (reghead): QuantizedConv2d(96, 2, kernel_size=(3, 3), stride=(1, 1), scale=0.005809594877064228, zero_point=129, padding=(1, 1))\n",
      "  )\n",
      "  (dequant): DeQuantize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(DH_m_int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['quant.scale', 'quant.zero_point', 'model_fp32.conv1.weight', 'model_fp32.conv1.bias', 'model_fp32.conv1.scale', 'model_fp32.conv1.zero_point', 'model_fp32.conv2.weight', 'model_fp32.conv2.bias', 'model_fp32.conv2.scale', 'model_fp32.conv2.zero_point', 'model_fp32.conv3.weight', 'model_fp32.conv3.bias', 'model_fp32.conv3.scale', 'model_fp32.conv3.zero_point', 'model_fp32.conv4.weight', 'model_fp32.conv4.bias', 'model_fp32.conv4.scale', 'model_fp32.conv4.zero_point', 'model_fp32.clshead.weight', 'model_fp32.clshead.bias', 'model_fp32.clshead.scale', 'model_fp32.clshead.zero_point', 'model_fp32.reghead.weight', 'model_fp32.reghead.bias', 'model_fp32.reghead.scale', 'model_fp32.reghead.zero_point'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DH_m_int8.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quant.scale  :  tensor([0.0684])\n",
      "quant.zero_point  :  tensor([62])\n",
      "model_fp32.conv1.weight  :  tensor([[[[ 0.0046,  0.0046,  0.0000],\n",
      "          [ 0.0034, -0.0034,  0.0023],\n",
      "          [-0.0034, -0.0023, -0.0046]],\n",
      "\n",
      "         [[-0.0046,  0.0080, -0.0046],\n",
      "          [ 0.0023,  0.0023,  0.0000],\n",
      "          [ 0.0023,  0.0115,  0.0057]],\n",
      "\n",
      "         [[-0.0011, -0.0034,  0.0011],\n",
      "          [ 0.0000,  0.0000,  0.0034],\n",
      "          [ 0.0023,  0.0069, -0.0023]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0092,  0.0046,  0.0046],\n",
      "          [ 0.0046,  0.0126,  0.0046],\n",
      "          [ 0.0092,  0.0034,  0.0046]],\n",
      "\n",
      "         [[ 0.0115,  0.0011,  0.0080],\n",
      "          [-0.0069, -0.0057,  0.0011],\n",
      "          [ 0.0034,  0.0057,  0.0046]],\n",
      "\n",
      "         [[-0.0103, -0.0034, -0.0057],\n",
      "          [-0.0011, -0.0034, -0.0011],\n",
      "          [ 0.0034,  0.0023, -0.0023]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0057,  0.0080,  0.0115],\n",
      "          [-0.0011,  0.0046,  0.0126],\n",
      "          [ 0.0080, -0.0011,  0.0046]],\n",
      "\n",
      "         [[-0.0046, -0.0138, -0.0092],\n",
      "          [-0.0046, -0.0126, -0.0057],\n",
      "          [-0.0080, -0.0103,  0.0000]],\n",
      "\n",
      "         [[-0.0046,  0.0023,  0.0011],\n",
      "          [ 0.0034,  0.0023, -0.0034],\n",
      "          [-0.0069, -0.0034, -0.0069]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0057, -0.0092,  0.0011],\n",
      "          [-0.0115, -0.0115, -0.0011],\n",
      "          [-0.0046, -0.0115,  0.0000]],\n",
      "\n",
      "         [[ 0.0034,  0.0092,  0.0011],\n",
      "          [-0.0057, -0.0034, -0.0069],\n",
      "          [-0.0034,  0.0023, -0.0011]],\n",
      "\n",
      "         [[ 0.0046,  0.0034,  0.0034],\n",
      "          [ 0.0046,  0.0046,  0.0000],\n",
      "          [-0.0023, -0.0011, -0.0034]]],\n",
      "\n",
      "\n",
      "        [[[-0.0011,  0.0011, -0.0046],\n",
      "          [ 0.0000,  0.0034, -0.0011],\n",
      "          [-0.0046, -0.0011, -0.0034]],\n",
      "\n",
      "         [[ 0.0034,  0.0057, -0.0034],\n",
      "          [ 0.0046,  0.0000, -0.0057],\n",
      "          [ 0.0034,  0.0034, -0.0023]],\n",
      "\n",
      "         [[-0.0034, -0.0023, -0.0011],\n",
      "          [-0.0023,  0.0000,  0.0000],\n",
      "          [ 0.0034,  0.0057,  0.0023]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0011,  0.0023,  0.0034],\n",
      "          [ 0.0046,  0.0046,  0.0046],\n",
      "          [ 0.0034,  0.0011, -0.0011]],\n",
      "\n",
      "         [[ 0.0080,  0.0023,  0.0046],\n",
      "          [-0.0057, -0.0069, -0.0034],\n",
      "          [ 0.0011,  0.0023, -0.0011]],\n",
      "\n",
      "         [[-0.0046, -0.0034, -0.0046],\n",
      "          [-0.0034, -0.0023, -0.0023],\n",
      "          [-0.0011,  0.0057, -0.0011]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0069, -0.0184,  0.0057],\n",
      "          [ 0.0046, -0.0138,  0.0092],\n",
      "          [ 0.0000, -0.0195,  0.0069]],\n",
      "\n",
      "         [[-0.0023, -0.0356,  0.0069],\n",
      "          [ 0.0115, -0.0057,  0.0011],\n",
      "          [-0.0184, -0.0149, -0.0080]],\n",
      "\n",
      "         [[ 0.0080,  0.0103, -0.0126],\n",
      "          [-0.0046,  0.0069, -0.0057],\n",
      "          [ 0.0069,  0.0034,  0.0115]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0046, -0.0080,  0.0057],\n",
      "          [ 0.0011,  0.0069,  0.0034],\n",
      "          [ 0.0023,  0.0103,  0.0034]],\n",
      "\n",
      "         [[ 0.0103,  0.0172,  0.0276],\n",
      "          [-0.0092,  0.0011,  0.0368],\n",
      "          [-0.0092, -0.0126,  0.0080]],\n",
      "\n",
      "         [[ 0.0149,  0.0011,  0.0023],\n",
      "          [ 0.0126, -0.0034,  0.0023],\n",
      "          [-0.0011,  0.0080,  0.0138]]],\n",
      "\n",
      "\n",
      "        [[[-0.0115, -0.0011, -0.0092],\n",
      "          [ 0.0057,  0.0069, -0.0069],\n",
      "          [ 0.0103,  0.0057, -0.0126]],\n",
      "\n",
      "         [[ 0.0046,  0.0023, -0.0069],\n",
      "          [ 0.0000,  0.0000, -0.0103],\n",
      "          [-0.0057, -0.0103, -0.0161]],\n",
      "\n",
      "         [[ 0.0000, -0.0080, -0.0046],\n",
      "          [-0.0046, -0.0011, -0.0115],\n",
      "          [ 0.0115,  0.0069,  0.0161]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0011, -0.0046,  0.0034],\n",
      "          [ 0.0023,  0.0023,  0.0046],\n",
      "          [-0.0023, -0.0011,  0.0092]],\n",
      "\n",
      "         [[ 0.0057,  0.0161,  0.0057],\n",
      "          [-0.0276, -0.0115, -0.0080],\n",
      "          [ 0.0092,  0.0115, -0.0046]],\n",
      "\n",
      "         [[-0.0092, -0.0011, -0.0115],\n",
      "          [ 0.0011,  0.0011, -0.0023],\n",
      "          [-0.0057,  0.0092,  0.0057]]],\n",
      "\n",
      "\n",
      "        [[[-0.0011, -0.0034, -0.0034],\n",
      "          [ 0.0149,  0.0000, -0.0069],\n",
      "          [ 0.0069, -0.0046, -0.0172]],\n",
      "\n",
      "         [[ 0.0011,  0.0034,  0.0069],\n",
      "          [ 0.0011, -0.0011,  0.0034],\n",
      "          [ 0.0069,  0.0046,  0.0103]],\n",
      "\n",
      "         [[ 0.0011, -0.0069, -0.0011],\n",
      "          [-0.0069, -0.0011,  0.0000],\n",
      "          [-0.0034, -0.0046, -0.0023]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0115,  0.0000, -0.0069],\n",
      "          [-0.0184, -0.0103, -0.0069],\n",
      "          [-0.0080, -0.0149, -0.0080]],\n",
      "\n",
      "         [[-0.0080, -0.0046, -0.0092],\n",
      "          [-0.0161, -0.0149, -0.0080],\n",
      "          [-0.0034, -0.0023, -0.0080]],\n",
      "\n",
      "         [[-0.0023,  0.0092,  0.0000],\n",
      "          [ 0.0069, -0.0034,  0.0000],\n",
      "          [-0.0080,  0.0011,  0.0023]]]], size=(144, 256, 3, 3),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.0011489674216136336, zero_point=0)\n",
      "model_fp32.conv1.bias  :  Parameter containing:\n",
      "tensor([-2.6987e-01, -5.1477e-02,  1.4927e-01, -1.0739e-01, -9.0461e-02,\n",
      "         1.8004e-01, -1.3748e-01,  2.8066e-02,  2.4261e-01,  1.9616e-01,\n",
      "         1.9314e-01,  8.4781e-02, -2.7715e-01, -1.8087e-01,  1.1079e-01,\n",
      "        -2.0252e-01,  8.5561e-02,  4.0332e-01, -2.0683e-01,  1.3523e-01,\n",
      "        -1.8678e-01,  1.0854e+00, -1.3342e-01,  8.8313e-03, -2.6373e-01,\n",
      "         1.4415e-01, -1.4987e-01, -3.5893e-02, -2.0677e-01,  2.8472e-01,\n",
      "         1.7430e-01,  4.7923e-01,  1.1680e-02,  4.0643e-02,  2.0895e-01,\n",
      "        -1.0183e-01,  1.2183e-01, -1.3186e-01, -6.4121e-02,  6.7420e-02,\n",
      "         1.6787e-03, -3.5737e-02, -1.1932e-01,  1.5144e-01,  1.6083e-01,\n",
      "         2.4631e-02,  3.3700e-02,  3.2194e-02, -2.0604e-02, -2.2640e-02,\n",
      "        -1.5251e-02,  1.0056e-01,  9.1792e-02,  7.4263e-02, -6.9101e-02,\n",
      "         1.4360e-02,  1.0809e-01,  2.3601e-01, -2.4805e-01,  2.1882e-02,\n",
      "        -5.6141e-02, -7.8586e-02,  9.7943e-02,  1.0954e-01,  8.7617e-03,\n",
      "         2.2771e-01, -3.9642e-01, -7.2256e-02, -5.4256e-02, -5.0431e-02,\n",
      "        -4.9468e-02, -7.9043e-02, -3.5218e-02,  1.2695e-01, -4.0634e-01,\n",
      "        -1.0697e-01,  2.0350e-01, -9.4354e-02,  8.1357e-03,  4.7655e-02,\n",
      "         7.7075e-02,  6.2907e-02,  2.7330e-01, -6.7004e-04,  3.1580e-01,\n",
      "         2.8941e-01, -3.9834e-02,  3.3483e-02,  3.9711e-01,  1.8172e-01,\n",
      "         9.0475e-02, -7.6446e-02, -9.6533e-02,  2.8280e-01,  9.0946e-02,\n",
      "        -2.0030e-02, -4.0197e-02,  1.7067e-01,  3.9122e-01,  2.3905e-01,\n",
      "         8.6678e-02, -8.0490e-03,  3.7274e-01, -1.5447e-01, -6.2491e-01,\n",
      "        -1.4309e-01,  3.6647e-01,  2.0922e-02,  3.5587e-02,  5.6867e-02,\n",
      "         1.3961e-01, -8.4045e-02,  7.4516e-02,  1.9215e-01,  4.3617e-03,\n",
      "         1.1811e-01,  2.0004e-01, -1.7580e-01,  2.2887e-01,  4.7996e-02,\n",
      "         2.2518e-01,  2.9782e-01, -1.2910e-01, -7.8729e-02,  1.1860e-01,\n",
      "         1.1901e-01, -1.8143e-01, -1.5455e-02,  5.6993e-03,  4.0365e-01,\n",
      "        -1.3705e-01,  1.7279e-02,  2.0216e-03, -4.7489e-02,  1.3790e-02,\n",
      "         2.5573e-01,  1.0648e-02,  1.3284e-02, -4.5859e-01, -7.2821e-03,\n",
      "        -1.3705e-02,  7.7273e-02,  1.7249e-02,  3.5039e-01],\n",
      "       requires_grad=True)\n",
      "model_fp32.conv1.scale  :  tensor(0.0338)\n",
      "model_fp32.conv1.zero_point  :  tensor(141)\n",
      "model_fp32.conv2.weight  :  tensor([[[[ 0.0024,  0.0012, -0.0071],\n",
      "          [ 0.0035, -0.0083, -0.0106],\n",
      "          [ 0.0177,  0.0012, -0.0083]],\n",
      "\n",
      "         [[ 0.0012,  0.0059,  0.0059],\n",
      "          [-0.0083, -0.0024,  0.0083],\n",
      "          [-0.0012, -0.0024,  0.0047]],\n",
      "\n",
      "         [[-0.0012, -0.0012, -0.0035],\n",
      "          [-0.0059,  0.0047, -0.0071],\n",
      "          [ 0.0118,  0.0059,  0.0106]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0083, -0.0035,  0.0035],\n",
      "          [-0.0071, -0.0142, -0.0012],\n",
      "          [ 0.0071,  0.0106,  0.0059]],\n",
      "\n",
      "         [[-0.0047, -0.0071, -0.0024],\n",
      "          [-0.0106, -0.0012,  0.0059],\n",
      "          [-0.0024, -0.0059,  0.0024]],\n",
      "\n",
      "         [[-0.0012, -0.0012, -0.0083],\n",
      "          [ 0.0000, -0.0071,  0.0035],\n",
      "          [-0.0083,  0.0000, -0.0012]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0118,  0.0106,  0.0083],\n",
      "          [ 0.0083,  0.0059,  0.0047],\n",
      "          [-0.0012, -0.0024, -0.0059]],\n",
      "\n",
      "         [[-0.0047, -0.0047,  0.0071],\n",
      "          [-0.0047,  0.0000,  0.0047],\n",
      "          [ 0.0154, -0.0083, -0.0059]],\n",
      "\n",
      "         [[-0.0166, -0.0012, -0.0142],\n",
      "          [-0.0071,  0.0035, -0.0012],\n",
      "          [-0.0154,  0.0095, -0.0142]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0012,  0.0012,  0.0059],\n",
      "          [ 0.0035, -0.0071, -0.0012],\n",
      "          [ 0.0035,  0.0071,  0.0095]],\n",
      "\n",
      "         [[-0.0106,  0.0000, -0.0059],\n",
      "          [-0.0083, -0.0024, -0.0083],\n",
      "          [-0.0047,  0.0071, -0.0035]],\n",
      "\n",
      "         [[-0.0012,  0.0095, -0.0095],\n",
      "          [-0.0047, -0.0035, -0.0071],\n",
      "          [ 0.0059, -0.0035, -0.0035]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0012, -0.0071, -0.0059],\n",
      "          [ 0.0012, -0.0047, -0.0035],\n",
      "          [-0.0012, -0.0024,  0.0000]],\n",
      "\n",
      "         [[-0.0035, -0.0012,  0.0035],\n",
      "          [ 0.0012,  0.0024, -0.0024],\n",
      "          [ 0.0012,  0.0035,  0.0035]],\n",
      "\n",
      "         [[-0.0012, -0.0047,  0.0012],\n",
      "          [ 0.0059,  0.0035,  0.0035],\n",
      "          [ 0.0047, -0.0024,  0.0024]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0024, -0.0024, -0.0012],\n",
      "          [-0.0024,  0.0035,  0.0035],\n",
      "          [ 0.0024,  0.0012, -0.0047]],\n",
      "\n",
      "         [[ 0.0047,  0.0012,  0.0047],\n",
      "          [ 0.0012,  0.0047, -0.0012],\n",
      "          [-0.0071, -0.0047, -0.0059]],\n",
      "\n",
      "         [[-0.0012, -0.0035,  0.0047],\n",
      "          [ 0.0035,  0.0012,  0.0047],\n",
      "          [-0.0047,  0.0000,  0.0035]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0059, -0.0047,  0.0012],\n",
      "          [-0.0012, -0.0012, -0.0035],\n",
      "          [ 0.0000, -0.0024, -0.0035]],\n",
      "\n",
      "         [[-0.0035, -0.0083, -0.0047],\n",
      "          [-0.0118, -0.0083, -0.0035],\n",
      "          [-0.0106, -0.0035,  0.0000]],\n",
      "\n",
      "         [[-0.0035,  0.0047,  0.0012],\n",
      "          [ 0.0024,  0.0071,  0.0035],\n",
      "          [-0.0012,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0047, -0.0083, -0.0012],\n",
      "          [ 0.0000,  0.0024, -0.0024],\n",
      "          [ 0.0071,  0.0035,  0.0024]],\n",
      "\n",
      "         [[ 0.0000,  0.0035, -0.0035],\n",
      "          [ 0.0000,  0.0012, -0.0035],\n",
      "          [-0.0035,  0.0000,  0.0012]],\n",
      "\n",
      "         [[ 0.0071,  0.0047,  0.0024],\n",
      "          [ 0.0000,  0.0012,  0.0024],\n",
      "          [-0.0047, -0.0047,  0.0012]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0035,  0.0000,  0.0024],\n",
      "          [ 0.0142,  0.0106,  0.0071],\n",
      "          [ 0.0035,  0.0012,  0.0000]],\n",
      "\n",
      "         [[-0.0012, -0.0047,  0.0000],\n",
      "          [ 0.0000,  0.0059,  0.0012],\n",
      "          [ 0.0035, -0.0024, -0.0024]],\n",
      "\n",
      "         [[-0.0047, -0.0035,  0.0012],\n",
      "          [ 0.0035,  0.0000,  0.0047],\n",
      "          [-0.0035,  0.0035, -0.0024]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0024,  0.0047,  0.0012],\n",
      "          [-0.0047,  0.0035, -0.0059],\n",
      "          [ 0.0047,  0.0024,  0.0035]],\n",
      "\n",
      "         [[-0.0024, -0.0012, -0.0012],\n",
      "          [ 0.0000,  0.0071,  0.0012],\n",
      "          [-0.0024,  0.0012, -0.0012]],\n",
      "\n",
      "         [[-0.0059, -0.0047, -0.0047],\n",
      "          [-0.0059, -0.0024,  0.0000],\n",
      "          [-0.0024, -0.0012, -0.0035]]],\n",
      "\n",
      "\n",
      "        [[[-0.0047, -0.0047, -0.0047],\n",
      "          [ 0.0047,  0.0000,  0.0071],\n",
      "          [-0.0024,  0.0012,  0.0024]],\n",
      "\n",
      "         [[-0.0083, -0.0035, -0.0071],\n",
      "          [ 0.0071,  0.0118,  0.0059],\n",
      "          [-0.0012,  0.0012,  0.0012]],\n",
      "\n",
      "         [[-0.0047, -0.0083, -0.0106],\n",
      "          [ 0.0012,  0.0000,  0.0012],\n",
      "          [ 0.0035,  0.0047,  0.0071]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0035,  0.0012,  0.0047],\n",
      "          [-0.0035, -0.0083,  0.0000],\n",
      "          [-0.0012, -0.0035,  0.0024]],\n",
      "\n",
      "         [[-0.0059, -0.0024, -0.0106],\n",
      "          [ 0.0059,  0.0118,  0.0024],\n",
      "          [ 0.0012,  0.0059, -0.0059]],\n",
      "\n",
      "         [[-0.0059, -0.0024, -0.0047],\n",
      "          [-0.0024,  0.0024,  0.0000],\n",
      "          [ 0.0024, -0.0024,  0.0012]]]], size=(96, 144, 3, 3),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.001182529958896339, zero_point=0)\n",
      "model_fp32.conv2.bias  :  Parameter containing:\n",
      "tensor([ 0.0390, -0.0039,  0.0106,  0.0414,  0.0046, -0.0083, -0.0407, -0.0006,\n",
      "         0.0286, -0.0384, -0.0401, -0.0861, -0.0353, -0.0188,  0.0790, -0.0677,\n",
      "         0.0732, -0.0024,  0.0131,  0.0105, -0.0131,  0.0377, -0.0015,  0.0825,\n",
      "         0.0270,  0.0357,  0.0657,  0.0002, -0.0043, -0.0146,  0.0015,  0.0172,\n",
      "        -0.0049, -0.0673, -0.0383, -0.0144, -0.0204,  0.0527, -0.0039, -0.0633,\n",
      "        -0.0559, -0.0254,  0.0337,  0.0612, -0.0174, -0.0247,  0.0304,  0.0494,\n",
      "         0.0106, -0.0180, -0.0024,  0.0084, -0.0063, -0.0101,  0.0037, -0.0117,\n",
      "        -0.0415,  0.0353, -0.0082, -0.0073, -0.0177,  0.0244, -0.0519, -0.0024,\n",
      "         0.0433,  0.0593, -0.0148,  0.0207,  0.0387, -0.0698, -0.0323, -0.0043,\n",
      "         0.0721, -0.0135, -0.0156,  0.0452, -0.0356,  0.0191, -0.0002,  0.0251,\n",
      "         0.0310, -0.0748,  0.0046, -0.0083,  0.0423, -0.0092, -0.0016, -0.0664,\n",
      "         0.0280, -0.0385, -0.0254, -0.0541,  0.0434,  0.0370,  0.0167,  0.0194],\n",
      "       requires_grad=True)\n",
      "model_fp32.conv2.scale  :  tensor(0.0225)\n",
      "model_fp32.conv2.zero_point  :  tensor(140)\n",
      "model_fp32.conv3.weight  :  tensor([[[[-0.0065,  0.0065,  0.0065],\n",
      "          [-0.0142, -0.0052, -0.0155],\n",
      "          [-0.0116, -0.0129,  0.0013]],\n",
      "\n",
      "         [[ 0.0039, -0.0103,  0.0181],\n",
      "          [ 0.0000, -0.0013,  0.0168],\n",
      "          [ 0.0026, -0.0065,  0.0052]],\n",
      "\n",
      "         [[-0.0065,  0.0090, -0.0052],\n",
      "          [ 0.0039,  0.0207,  0.0116],\n",
      "          [-0.0039,  0.0039, -0.0026]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0052, -0.0052,  0.0039],\n",
      "          [-0.0065,  0.0116,  0.0065],\n",
      "          [-0.0026, -0.0090,  0.0065]],\n",
      "\n",
      "         [[ 0.0078, -0.0026,  0.0013],\n",
      "          [ 0.0065,  0.0116,  0.0026],\n",
      "          [-0.0039,  0.0065,  0.0090]],\n",
      "\n",
      "         [[-0.0026, -0.0026,  0.0013],\n",
      "          [ 0.0078,  0.0090, -0.0129],\n",
      "          [-0.0078, -0.0039,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0052, -0.0090,  0.0000],\n",
      "          [ 0.0026,  0.0090,  0.0155],\n",
      "          [ 0.0039,  0.0103,  0.0116]],\n",
      "\n",
      "         [[-0.0013, -0.0090,  0.0065],\n",
      "          [ 0.0142, -0.0103,  0.0116],\n",
      "          [ 0.0142,  0.0000,  0.0065]],\n",
      "\n",
      "         [[ 0.0052,  0.0065,  0.0013],\n",
      "          [-0.0065, -0.0103, -0.0026],\n",
      "          [ 0.0052, -0.0078,  0.0039]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0065, -0.0013,  0.0039],\n",
      "          [-0.0013,  0.0000,  0.0013],\n",
      "          [-0.0026,  0.0026,  0.0013]],\n",
      "\n",
      "         [[ 0.0039,  0.0026, -0.0078],\n",
      "          [-0.0168, -0.0142, -0.0065],\n",
      "          [-0.0078, -0.0065, -0.0039]],\n",
      "\n",
      "         [[ 0.0013,  0.0052,  0.0065],\n",
      "          [-0.0103, -0.0013, -0.0052],\n",
      "          [ 0.0078,  0.0103,  0.0013]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0065, -0.0090, -0.0065],\n",
      "          [-0.0039, -0.0065,  0.0000],\n",
      "          [ 0.0090, -0.0013,  0.0090]],\n",
      "\n",
      "         [[ 0.0000,  0.0013,  0.0026],\n",
      "          [ 0.0065, -0.0065, -0.0013],\n",
      "          [-0.0013, -0.0026, -0.0026]],\n",
      "\n",
      "         [[-0.0078, -0.0039, -0.0052],\n",
      "          [-0.0078, -0.0142, -0.0220],\n",
      "          [ 0.0000, -0.0039, -0.0013]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0039, -0.0090, -0.0026],\n",
      "          [-0.0052, -0.0116, -0.0078],\n",
      "          [-0.0065, -0.0039,  0.0013]],\n",
      "\n",
      "         [[ 0.0039,  0.0039,  0.0090],\n",
      "          [ 0.0116,  0.0090,  0.0065],\n",
      "          [ 0.0000, -0.0026,  0.0026]],\n",
      "\n",
      "         [[ 0.0000,  0.0026,  0.0026],\n",
      "          [ 0.0078,  0.0013,  0.0039],\n",
      "          [ 0.0090,  0.0026,  0.0065]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0052,  0.0052],\n",
      "          [ 0.0039, -0.0065, -0.0052],\n",
      "          [-0.0039,  0.0065, -0.0052]],\n",
      "\n",
      "         [[ 0.0052,  0.0116, -0.0065],\n",
      "          [ 0.0065,  0.0116, -0.0103],\n",
      "          [-0.0116,  0.0039, -0.0142]],\n",
      "\n",
      "         [[-0.0090, -0.0039,  0.0116],\n",
      "          [ 0.0052,  0.0026,  0.0039],\n",
      "          [ 0.0039, -0.0065,  0.0129]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0052,  0.0039,  0.0052],\n",
      "          [ 0.0000,  0.0039, -0.0078],\n",
      "          [-0.0103, -0.0039, -0.0168]],\n",
      "\n",
      "         [[-0.0090,  0.0039,  0.0052],\n",
      "          [ 0.0000,  0.0052,  0.0078],\n",
      "          [-0.0065, -0.0026,  0.0026]],\n",
      "\n",
      "         [[-0.0078,  0.0026,  0.0000],\n",
      "          [ 0.0013,  0.0039,  0.0116],\n",
      "          [ 0.0065,  0.0052,  0.0078]]],\n",
      "\n",
      "\n",
      "        [[[-0.0065,  0.0013, -0.0039],\n",
      "          [-0.0090,  0.0039,  0.0052],\n",
      "          [-0.0090, -0.0013, -0.0090]],\n",
      "\n",
      "         [[-0.0052,  0.0129, -0.0026],\n",
      "          [ 0.0000,  0.0065,  0.0052],\n",
      "          [-0.0065, -0.0026, -0.0116]],\n",
      "\n",
      "         [[-0.0026,  0.0039,  0.0090],\n",
      "          [-0.0052,  0.0000,  0.0233],\n",
      "          [ 0.0013,  0.0026,  0.0065]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0052,  0.0026,  0.0065],\n",
      "          [-0.0013,  0.0090,  0.0039],\n",
      "          [-0.0039,  0.0039,  0.0026]],\n",
      "\n",
      "         [[-0.0103, -0.0142, -0.0052],\n",
      "          [-0.0052, -0.0078, -0.0078],\n",
      "          [-0.0052, -0.0013,  0.0026]],\n",
      "\n",
      "         [[-0.0026, -0.0026,  0.0026],\n",
      "          [ 0.0039, -0.0052,  0.0000],\n",
      "          [ 0.0039, -0.0078, -0.0078]]],\n",
      "\n",
      "\n",
      "        [[[-0.0142, -0.0155, -0.0103],\n",
      "          [-0.0078, -0.0103,  0.0000],\n",
      "          [ 0.0026, -0.0026,  0.0026]],\n",
      "\n",
      "         [[-0.0168,  0.0013,  0.0052],\n",
      "          [ 0.0052,  0.0065, -0.0013],\n",
      "          [-0.0155,  0.0039,  0.0000]],\n",
      "\n",
      "         [[ 0.0194,  0.0026,  0.0090],\n",
      "          [ 0.0052, -0.0052, -0.0078],\n",
      "          [-0.0052,  0.0052,  0.0039]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0026,  0.0026,  0.0142],\n",
      "          [ 0.0090, -0.0013,  0.0026],\n",
      "          [-0.0090, -0.0103, -0.0039]],\n",
      "\n",
      "         [[-0.0013,  0.0026,  0.0026],\n",
      "          [-0.0090, -0.0078, -0.0090],\n",
      "          [-0.0065, -0.0065,  0.0052]],\n",
      "\n",
      "         [[ 0.0116,  0.0026, -0.0013],\n",
      "          [-0.0052,  0.0026,  0.0026],\n",
      "          [-0.0065, -0.0039,  0.0039]]]], size=(96, 96, 3, 3),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.0012923858594149351, zero_point=0)\n",
      "model_fp32.conv3.bias  :  Parameter containing:\n",
      "tensor([-0.0114, -0.0078, -0.0243,  0.1016,  0.0647, -0.0011, -0.0073, -0.0099,\n",
      "        -0.0361,  0.0095,  0.0240, -0.0361,  0.0343, -0.0171, -0.0310, -0.0218,\n",
      "         0.0148, -0.1059, -0.0678, -0.0774, -0.0022, -0.1058, -0.1633,  0.0625,\n",
      "        -0.0318,  0.0832, -0.0486,  0.0570, -0.0236, -0.0324,  0.1055, -0.0167,\n",
      "        -0.0159,  0.0536,  0.0047,  0.0320,  0.0130,  0.0452, -0.0220,  0.0703,\n",
      "         0.0362,  0.0415,  0.0847,  0.0490, -0.0256, -0.0522,  0.0050,  0.0304,\n",
      "         0.0095,  0.0736, -0.0038, -0.0615, -0.0778, -0.0266,  0.0525,  0.0495,\n",
      "         0.0905, -0.0515, -0.0416,  0.0037, -0.0270, -0.0675,  0.0393,  0.0321,\n",
      "         0.0121,  0.0166,  0.1015, -0.0202, -0.0284,  0.0212,  0.0847,  0.0140,\n",
      "         0.0185,  0.0127,  0.0367,  0.0515, -0.0501,  0.0143, -0.0273, -0.0553,\n",
      "        -0.0235,  0.0144, -0.0729,  0.0408, -0.0356,  0.0530, -0.1196, -0.0327,\n",
      "        -0.0845, -0.0711,  0.0147, -0.0525, -0.0196,  0.0017,  0.0413, -0.1443],\n",
      "       requires_grad=True)\n",
      "model_fp32.conv3.scale  :  tensor(0.0182)\n",
      "model_fp32.conv3.zero_point  :  tensor(129)\n",
      "model_fp32.conv4.weight  :  tensor([[[[ 0.0008, -0.0076, -0.0085],\n",
      "          [ 0.0025, -0.0051, -0.0025],\n",
      "          [-0.0025, -0.0017, -0.0042]],\n",
      "\n",
      "         [[-0.0008,  0.0000,  0.0059],\n",
      "          [-0.0051,  0.0042,  0.0034],\n",
      "          [ 0.0025,  0.0042,  0.0042]],\n",
      "\n",
      "         [[ 0.0025,  0.0102,  0.0093],\n",
      "          [ 0.0017,  0.0042,  0.0017],\n",
      "          [ 0.0000,  0.0093,  0.0034]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0051, -0.0017,  0.0059],\n",
      "          [-0.0051, -0.0034, -0.0051],\n",
      "          [-0.0017, -0.0068,  0.0000]],\n",
      "\n",
      "         [[-0.0051,  0.0000,  0.0000],\n",
      "          [-0.0068, -0.0076, -0.0025],\n",
      "          [-0.0085, -0.0102, -0.0093]],\n",
      "\n",
      "         [[ 0.0000, -0.0034,  0.0051],\n",
      "          [-0.0025,  0.0008,  0.0008],\n",
      "          [ 0.0000, -0.0076, -0.0144]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0076,  0.0017, -0.0034],\n",
      "          [ 0.0017,  0.0042,  0.0051],\n",
      "          [-0.0008,  0.0034,  0.0110]],\n",
      "\n",
      "         [[ 0.0076,  0.0000,  0.0025],\n",
      "          [ 0.0085, -0.0017,  0.0000],\n",
      "          [ 0.0102,  0.0042, -0.0085]],\n",
      "\n",
      "         [[-0.0110, -0.0051, -0.0025],\n",
      "          [-0.0051, -0.0136,  0.0008],\n",
      "          [-0.0017, -0.0110, -0.0025]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0051, -0.0025,  0.0025],\n",
      "          [ 0.0025,  0.0093,  0.0000],\n",
      "          [ 0.0093,  0.0110, -0.0008]],\n",
      "\n",
      "         [[ 0.0076, -0.0008,  0.0025],\n",
      "          [ 0.0102,  0.0085, -0.0008],\n",
      "          [-0.0025,  0.0119,  0.0042]],\n",
      "\n",
      "         [[-0.0008, -0.0025, -0.0017],\n",
      "          [ 0.0068,  0.0085,  0.0034],\n",
      "          [-0.0059, -0.0042,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0051, -0.0127,  0.0034],\n",
      "          [-0.0144, -0.0136, -0.0051],\n",
      "          [-0.0076,  0.0042,  0.0042]],\n",
      "\n",
      "         [[ 0.0068,  0.0008, -0.0076],\n",
      "          [ 0.0229, -0.0025, -0.0051],\n",
      "          [ 0.0017, -0.0034, -0.0102]],\n",
      "\n",
      "         [[ 0.0017, -0.0076,  0.0102],\n",
      "          [-0.0212, -0.0068, -0.0170],\n",
      "          [-0.0127, -0.0034, -0.0170]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0042, -0.0059, -0.0110],\n",
      "          [ 0.0051, -0.0093, -0.0212],\n",
      "          [-0.0025, -0.0127, -0.0178]],\n",
      "\n",
      "         [[ 0.0110, -0.0017,  0.0102],\n",
      "          [ 0.0085,  0.0102, -0.0017],\n",
      "          [ 0.0153, -0.0042,  0.0136]],\n",
      "\n",
      "         [[ 0.0153,  0.0034,  0.0017],\n",
      "          [-0.0017,  0.0017,  0.0076],\n",
      "          [ 0.0000,  0.0085,  0.0221]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0068, -0.0076, -0.0127],\n",
      "          [ 0.0102,  0.0085,  0.0025],\n",
      "          [ 0.0034, -0.0110, -0.0034]],\n",
      "\n",
      "         [[-0.0093, -0.0042,  0.0110],\n",
      "          [-0.0212,  0.0042, -0.0068],\n",
      "          [ 0.0051,  0.0034, -0.0025]],\n",
      "\n",
      "         [[-0.0017, -0.0008,  0.0034],\n",
      "          [ 0.0034,  0.0136, -0.0008],\n",
      "          [ 0.0178, -0.0017, -0.0008]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0025,  0.0102,  0.0008],\n",
      "          [-0.0042,  0.0093,  0.0008],\n",
      "          [-0.0110, -0.0110, -0.0059]],\n",
      "\n",
      "         [[ 0.0093, -0.0068, -0.0076],\n",
      "          [-0.0025, -0.0161, -0.0017],\n",
      "          [ 0.0059,  0.0008, -0.0068]],\n",
      "\n",
      "         [[ 0.0000,  0.0025,  0.0025],\n",
      "          [ 0.0000, -0.0068, -0.0076],\n",
      "          [ 0.0076, -0.0025, -0.0144]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0051,  0.0051,  0.0093],\n",
      "          [-0.0127, -0.0110,  0.0017],\n",
      "          [-0.0034, -0.0017,  0.0000]],\n",
      "\n",
      "         [[ 0.0017,  0.0025, -0.0008],\n",
      "          [ 0.0059,  0.0059, -0.0059],\n",
      "          [-0.0008, -0.0034, -0.0085]],\n",
      "\n",
      "         [[ 0.0059, -0.0025, -0.0017],\n",
      "          [ 0.0008, -0.0059,  0.0025],\n",
      "          [-0.0059, -0.0042, -0.0042]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0059,  0.0017, -0.0093],\n",
      "          [ 0.0068,  0.0059, -0.0059],\n",
      "          [-0.0042,  0.0017,  0.0068]],\n",
      "\n",
      "         [[ 0.0025,  0.0017, -0.0068],\n",
      "          [-0.0068,  0.0034,  0.0068],\n",
      "          [-0.0059, -0.0042, -0.0042]],\n",
      "\n",
      "         [[ 0.0076,  0.0136,  0.0000],\n",
      "          [-0.0008,  0.0068,  0.0085],\n",
      "          [-0.0093, -0.0102, -0.0102]]],\n",
      "\n",
      "\n",
      "        [[[-0.0034,  0.0059,  0.0051],\n",
      "          [ 0.0000,  0.0034,  0.0102],\n",
      "          [-0.0034, -0.0025,  0.0034]],\n",
      "\n",
      "         [[-0.0025, -0.0017, -0.0034],\n",
      "          [ 0.0102,  0.0017, -0.0008],\n",
      "          [-0.0017,  0.0000,  0.0017]],\n",
      "\n",
      "         [[-0.0119, -0.0161, -0.0042],\n",
      "          [ 0.0017, -0.0017,  0.0042],\n",
      "          [-0.0059, -0.0034,  0.0034]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0059, -0.0051, -0.0068],\n",
      "          [ 0.0085,  0.0008, -0.0034],\n",
      "          [ 0.0051,  0.0042,  0.0008]],\n",
      "\n",
      "         [[ 0.0025, -0.0017,  0.0051],\n",
      "          [-0.0008,  0.0051,  0.0008],\n",
      "          [ 0.0059, -0.0034,  0.0042]],\n",
      "\n",
      "         [[-0.0042, -0.0034, -0.0025],\n",
      "          [ 0.0076,  0.0076,  0.0102],\n",
      "          [-0.0085, -0.0102, -0.0068]]]], size=(96, 96, 3, 3),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.0008491309708915651, zero_point=0)\n",
      "model_fp32.conv4.bias  :  Parameter containing:\n",
      "tensor([ 0.0571, -0.0795, -0.0384, -0.0752, -0.0612, -0.1094, -0.1270, -0.0878,\n",
      "        -0.0997,  0.1250,  0.0331,  0.1411,  0.1413, -0.0676,  0.1916, -0.0996,\n",
      "         0.0023, -0.0497, -0.0243,  0.1337, -0.0974, -0.0891, -0.1053,  0.0290,\n",
      "         0.0446, -0.2046,  0.1051, -0.0948,  0.0933,  0.0398,  0.1063, -0.1701,\n",
      "         0.0696, -0.1166,  0.1477,  0.1263, -0.1572,  0.0257,  0.0744, -0.0250,\n",
      "        -0.1801,  0.1334, -0.1078, -0.0904, -0.0934,  0.1452,  0.0443,  0.0306,\n",
      "        -0.0714, -0.1076, -0.0190,  0.0936, -0.0794,  0.0977, -0.0886, -0.1598,\n",
      "        -0.0361,  0.0362,  0.1417,  0.0730, -0.0375,  0.1497, -0.1387,  0.0306,\n",
      "         0.0935,  0.0824, -0.0249, -0.0305,  0.1024,  0.0679,  0.1182,  0.0745,\n",
      "        -0.0996, -0.2091,  0.0889,  0.0252,  0.2250, -0.1031,  0.1334, -0.1248,\n",
      "         0.1492, -0.0951, -0.0934, -0.0923, -0.1341, -0.0993, -0.0417,  0.1087,\n",
      "         0.0224, -0.0679, -0.0629,  0.0542, -0.1063,  0.1196, -0.0924, -0.0765],\n",
      "       requires_grad=True)\n",
      "model_fp32.conv4.scale  :  tensor(0.0117)\n",
      "model_fp32.conv4.zero_point  :  tensor(146)\n",
      "model_fp32.clshead.weight  :  tensor([[[[-0.0979, -0.1486, -0.1250],\n",
      "          [ 0.0000, -0.0777, -0.0946],\n",
      "          [ 0.0135, -0.0338, -0.0946]],\n",
      "\n",
      "         [[ 0.1013,  0.0844,  0.0709],\n",
      "          [ 0.0979,  0.0169, -0.0034],\n",
      "          [ 0.1182,  0.0405,  0.0304]],\n",
      "\n",
      "         [[ 0.0811,  0.0811,  0.1621],\n",
      "          [ 0.1013,  0.1385,  0.2499],\n",
      "          [ 0.0507, -0.0405,  0.0439]],\n",
      "\n",
      "         [[-0.0540,  0.0034,  0.0473],\n",
      "          [ 0.0338,  0.0507,  0.0844],\n",
      "          [ 0.1283,  0.1891,  0.1486]],\n",
      "\n",
      "         [[-0.1148,  0.0439,  0.1520],\n",
      "          [-0.1317,  0.0811,  0.3242],\n",
      "          [-0.0675,  0.0811,  0.2499]],\n",
      "\n",
      "         [[ 0.2634,  0.2026,  0.2533],\n",
      "          [ 0.1554,  0.0236,  0.1418],\n",
      "          [ 0.0203, -0.1013,  0.0203]],\n",
      "\n",
      "         [[-0.0270, -0.1486, -0.1148],\n",
      "          [ 0.1047,  0.1047,  0.0608],\n",
      "          [ 0.2195,  0.4019,  0.3715]],\n",
      "\n",
      "         [[ 0.1047,  0.1587,  0.0811],\n",
      "          [ 0.1351,  0.1418,  0.0135],\n",
      "          [ 0.1182,  0.0675,  0.0507]],\n",
      "\n",
      "         [[ 0.1081,  0.0709, -0.0034],\n",
      "          [ 0.1081,  0.1283,  0.0000],\n",
      "          [ 0.1486,  0.1959,  0.1182]],\n",
      "\n",
      "         [[-0.0270,  0.0304, -0.0743],\n",
      "          [-0.0236, -0.0304, -0.1993],\n",
      "          [-0.0743, -0.1013, -0.2465]],\n",
      "\n",
      "         [[ 0.1250,  0.0473, -0.0439],\n",
      "          [ 0.0540, -0.1351, -0.2600],\n",
      "          [ 0.1857,  0.0236, -0.0912]],\n",
      "\n",
      "         [[-0.2094,  0.0135, -0.1554],\n",
      "          [-0.2330,  0.0507, -0.1283],\n",
      "          [-0.2972, -0.1621, -0.3175]],\n",
      "\n",
      "         [[-0.1351, -0.1385, -0.0034],\n",
      "          [-0.0979, -0.0878,  0.0101],\n",
      "          [-0.2094, -0.3681, -0.1554]],\n",
      "\n",
      "         [[ 0.0979,  0.1216,  0.0979],\n",
      "          [ 0.0946,  0.1081,  0.0236],\n",
      "          [ 0.1081,  0.0709,  0.0439]],\n",
      "\n",
      "         [[-0.2364, -0.2600, -0.3445],\n",
      "          [-0.0608, -0.0979, -0.2499],\n",
      "          [-0.1993, -0.1621, -0.3715]],\n",
      "\n",
      "         [[ 0.2297,  0.2364,  0.1554],\n",
      "          [ 0.0946,  0.0236, -0.1013],\n",
      "          [ 0.1452,  0.1385,  0.0270]],\n",
      "\n",
      "         [[-0.0777, -0.0777, -0.0675],\n",
      "          [-0.0169, -0.0946, -0.1655],\n",
      "          [-0.0777, -0.1554, -0.1655]],\n",
      "\n",
      "         [[-0.1182, -0.0507, -0.0169],\n",
      "          [-0.0540,  0.1148,  0.0912],\n",
      "          [ 0.1047,  0.2904,  0.2026]],\n",
      "\n",
      "         [[-0.0743, -0.0574, -0.0574],\n",
      "          [ 0.0574,  0.1114,  0.0371],\n",
      "          [ 0.0811,  0.1216,  0.0608]],\n",
      "\n",
      "         [[-0.2026, -0.0878, -0.2398],\n",
      "          [-0.1756,  0.0203, -0.2161],\n",
      "          [-0.2263, -0.0777, -0.1756]],\n",
      "\n",
      "         [[ 0.2837,  0.0878,  0.1317],\n",
      "          [ 0.3208,  0.0270,  0.0169],\n",
      "          [ 0.2702,  0.0000, -0.0034]],\n",
      "\n",
      "         [[-0.0811, -0.0844, -0.0473],\n",
      "          [ 0.0169,  0.1148,  0.0946],\n",
      "          [ 0.2702,  0.4289,  0.2263]],\n",
      "\n",
      "         [[ 0.2567,  0.2634,  0.2195],\n",
      "          [ 0.0203, -0.0642, -0.0540],\n",
      "          [ 0.1250,  0.2263,  0.2094]],\n",
      "\n",
      "         [[-0.1959, -0.2364, -0.2026],\n",
      "          [-0.0371, -0.0844, -0.1452],\n",
      "          [ 0.0912,  0.0743,  0.0236]],\n",
      "\n",
      "         [[ 0.0338,  0.0574, -0.1047],\n",
      "          [-0.0338, -0.0675, -0.2398],\n",
      "          [-0.1148, -0.0675, -0.1418]],\n",
      "\n",
      "         [[-0.1418, -0.1486,  0.2871],\n",
      "          [ 0.0169, -0.0034,  0.4222],\n",
      "          [ 0.0709,  0.0000,  0.3040]],\n",
      "\n",
      "         [[-0.2229, -0.1317, -0.1689],\n",
      "          [-0.2803, -0.0338, -0.0709],\n",
      "          [-0.1385, -0.0338, -0.0236]],\n",
      "\n",
      "         [[ 0.1013,  0.1047,  0.1452],\n",
      "          [ 0.1081,  0.0371,  0.1756],\n",
      "          [ 0.1824,  0.1283,  0.1722]],\n",
      "\n",
      "         [[-0.1655, -0.1114, -0.2533],\n",
      "          [-0.1655, -0.0507, -0.2229],\n",
      "          [-0.0979, -0.0912, -0.1385]],\n",
      "\n",
      "         [[-0.0439, -0.0034, -0.0270],\n",
      "          [-0.1317, -0.1351, -0.0169],\n",
      "          [-0.1554, -0.0946, -0.1081]],\n",
      "\n",
      "         [[-0.0912, -0.1689, -0.1587],\n",
      "          [ 0.0169, -0.0304, -0.0743],\n",
      "          [-0.1182, -0.2398, -0.1790]],\n",
      "\n",
      "         [[ 0.2060,  0.3479,  0.2634],\n",
      "          [ 0.0034,  0.0473,  0.1418],\n",
      "          [ 0.2229,  0.3681,  0.3006]],\n",
      "\n",
      "         [[-0.1182, -0.1148, -0.0946],\n",
      "          [-0.0811, -0.0405,  0.0304],\n",
      "          [-0.1148, -0.1081, -0.0034]],\n",
      "\n",
      "         [[ 0.2769,  0.1351, -0.0777],\n",
      "          [ 0.1790, -0.0135, -0.3073],\n",
      "          [ 0.2600,  0.2195,  0.0000]],\n",
      "\n",
      "         [[-0.0912, -0.0135, -0.1250],\n",
      "          [-0.0642,  0.0405, -0.1722],\n",
      "          [-0.2499, -0.2769, -0.3445]],\n",
      "\n",
      "         [[-0.1114, -0.1317, -0.0979],\n",
      "          [-0.0338, -0.0101, -0.0507],\n",
      "          [-0.0135, -0.0709, -0.1114]],\n",
      "\n",
      "         [[ 0.2330,  0.2398,  0.2398],\n",
      "          [ 0.2161,  0.1081,  0.1857],\n",
      "          [ 0.0912, -0.0878,  0.0507]],\n",
      "\n",
      "         [[-0.0371, -0.0878, -0.1114],\n",
      "          [ 0.0135, -0.0203, -0.1452],\n",
      "          [ 0.0034, -0.0979, -0.1655]],\n",
      "\n",
      "         [[-0.1317, -0.4120, -0.2330],\n",
      "          [-0.0507, -0.1959, -0.1925],\n",
      "          [ 0.2972,  0.2195, -0.0034]],\n",
      "\n",
      "         [[ 0.1655,  0.1148,  0.0270],\n",
      "          [ 0.2837,  0.0844, -0.0270],\n",
      "          [ 0.1047,  0.0203, -0.0844]],\n",
      "\n",
      "         [[ 0.1013,  0.0439,  0.2871],\n",
      "          [ 0.0574, -0.1216,  0.1790],\n",
      "          [ 0.2904,  0.2871,  0.3276]],\n",
      "\n",
      "         [[-0.1554, -0.0675, -0.1925],\n",
      "          [-0.0912,  0.0101, -0.1689],\n",
      "          [-0.0034,  0.0540, -0.1452]],\n",
      "\n",
      "         [[ 0.1993,  0.4120,  0.2094],\n",
      "          [ 0.0608,  0.1452,  0.1148],\n",
      "          [-0.0675, -0.2161, -0.0642]],\n",
      "\n",
      "         [[ 0.2398,  0.0574, -0.0709],\n",
      "          [ 0.3546,  0.0270, -0.2398],\n",
      "          [ 0.3377,  0.0473, -0.1925]],\n",
      "\n",
      "         [[ 0.1587,  0.0878,  0.1216],\n",
      "          [ 0.1756,  0.0946,  0.0608],\n",
      "          [ 0.1587,  0.0946,  0.0540]],\n",
      "\n",
      "         [[-0.0979, -0.1587, -0.0979],\n",
      "          [-0.1554, -0.0642, -0.0371],\n",
      "          [-0.1925, -0.1418, -0.0675]],\n",
      "\n",
      "         [[-0.0675,  0.0304,  0.0304],\n",
      "          [-0.1114, -0.0675,  0.0101],\n",
      "          [-0.1587, -0.1790, -0.1081]],\n",
      "\n",
      "         [[-0.0912, -0.1385, -0.0777],\n",
      "          [-0.0608, -0.1114, -0.0507],\n",
      "          [-0.0405, -0.0675,  0.0101]],\n",
      "\n",
      "         [[-0.0540, -0.1520, -0.0642],\n",
      "          [ 0.1182,  0.0642,  0.1317],\n",
      "          [ 0.2297,  0.2364,  0.2330]],\n",
      "\n",
      "         [[ 0.1250,  0.2128,  0.1689],\n",
      "          [ 0.0439, -0.0101,  0.0811],\n",
      "          [ 0.1182,  0.1013,  0.0878]],\n",
      "\n",
      "         [[-0.0507,  0.1081,  0.1081],\n",
      "          [-0.1047,  0.1081,  0.0946],\n",
      "          [-0.0709,  0.0642,  0.0000]],\n",
      "\n",
      "         [[-0.0540,  0.0709, -0.0371],\n",
      "          [-0.0979, -0.0203, -0.0912],\n",
      "          [-0.3715, -0.3073, -0.1486]],\n",
      "\n",
      "         [[-0.0135,  0.0878,  0.0811],\n",
      "          [-0.0101,  0.0675,  0.0844],\n",
      "          [ 0.1722,  0.2736,  0.1587]],\n",
      "\n",
      "         [[ 0.0371, -0.0101, -0.1216],\n",
      "          [ 0.0169, -0.0811, -0.2702],\n",
      "          [-0.1013, -0.1891, -0.2026]],\n",
      "\n",
      "         [[ 0.0574,  0.0912,  0.1520],\n",
      "          [-0.0338,  0.0034,  0.1182],\n",
      "          [ 0.1182,  0.2600,  0.2026]],\n",
      "\n",
      "         [[ 0.1554,  0.1790,  0.3006],\n",
      "          [ 0.0878,  0.0642,  0.3073],\n",
      "          [-0.0709, -0.0608,  0.2803]],\n",
      "\n",
      "         [[ 0.1317,  0.1283,  0.1520],\n",
      "          [ 0.0642,  0.0912,  0.0844],\n",
      "          [ 0.0540,  0.0574,  0.0236]],\n",
      "\n",
      "         [[-0.0946, -0.1554, -0.0743],\n",
      "          [-0.0608, -0.1013, -0.0507],\n",
      "          [-0.0270, -0.0844, -0.0338]],\n",
      "\n",
      "         [[-0.2229, -0.0979, -0.0844],\n",
      "          [-0.2600, -0.0270,  0.0203],\n",
      "          [-0.1655,  0.0068,  0.0540]],\n",
      "\n",
      "         [[ 0.1114,  0.2026,  0.0507],\n",
      "          [-0.1047, -0.0709, -0.1452],\n",
      "          [-0.2736, -0.2769, -0.2263]],\n",
      "\n",
      "         [[ 0.0979,  0.1520,  0.0912],\n",
      "          [-0.0101,  0.0709,  0.0101],\n",
      "          [ 0.1013,  0.1182,  0.0203]],\n",
      "\n",
      "         [[-0.1756, -0.0304, -0.1452],\n",
      "          [-0.2229,  0.0709,  0.0507],\n",
      "          [-0.3073, -0.1250, -0.1824]],\n",
      "\n",
      "         [[-0.0135,  0.1317,  0.1486],\n",
      "          [-0.0709,  0.1114,  0.1756],\n",
      "          [ 0.0574,  0.1216,  0.1857]],\n",
      "\n",
      "         [[-0.1114, -0.0675, -0.0912],\n",
      "          [-0.0844, -0.0811, -0.0371],\n",
      "          [-0.0743, -0.0642, -0.0675]],\n",
      "\n",
      "         [[-0.0946, -0.0473, -0.0979],\n",
      "          [-0.0777,  0.0270, -0.0169],\n",
      "          [-0.1182, -0.1722, -0.1216]],\n",
      "\n",
      "         [[-0.1047, -0.0743, -0.1722],\n",
      "          [ 0.0912, -0.0034, -0.1621],\n",
      "          [ 0.0068, -0.0811, -0.1993]],\n",
      "\n",
      "         [[ 0.0574,  0.0675,  0.0777],\n",
      "          [ 0.0101,  0.0844,  0.0338],\n",
      "          [ 0.1317,  0.2128,  0.1722]],\n",
      "\n",
      "         [[ 0.0574,  0.0101,  0.0473],\n",
      "          [ 0.0878,  0.1081,  0.0574],\n",
      "          [ 0.1351,  0.1148,  0.0473]],\n",
      "\n",
      "         [[-0.1891, -0.2567, -0.2533],\n",
      "          [-0.2533, -0.0338, -0.0068],\n",
      "          [-0.0811,  0.1824,  0.1182]],\n",
      "\n",
      "         [[-0.1182, -0.1081, -0.1351],\n",
      "          [-0.1317, -0.0675, -0.0844],\n",
      "          [-0.0507,  0.0811,  0.0574]],\n",
      "\n",
      "         [[-0.2128, -0.2398, -0.2364],\n",
      "          [-0.0811,  0.0507, -0.0304],\n",
      "          [-0.2938, -0.2432, -0.1452]],\n",
      "\n",
      "         [[-0.1283, -0.1486, -0.2297],\n",
      "          [-0.0844,  0.0574, -0.1655],\n",
      "          [-0.2094, -0.1824, -0.2026]],\n",
      "\n",
      "         [[ 0.2195,  0.3073,  0.2769],\n",
      "          [ 0.1993, -0.0101,  0.0507],\n",
      "          [ 0.0709, -0.2128, -0.0236]],\n",
      "\n",
      "         [[ 0.0371, -0.0473,  0.0236],\n",
      "          [ 0.1621,  0.1047,  0.2026],\n",
      "          [ 0.2128,  0.2026,  0.1554]],\n",
      "\n",
      "         [[-0.0101, -0.1520, -0.1891],\n",
      "          [ 0.1891, -0.0642, -0.2398],\n",
      "          [ 0.0473, -0.1621, -0.2533]],\n",
      "\n",
      "         [[-0.0912, -0.0608, -0.1013],\n",
      "          [-0.0912, -0.0574, -0.0642],\n",
      "          [-0.1047, -0.0811, -0.0507]],\n",
      "\n",
      "         [[-0.2161, -0.1351, -0.2398],\n",
      "          [-0.0709,  0.1114, -0.0642],\n",
      "          [-0.3546, -0.4019, -0.3310]],\n",
      "\n",
      "         [[ 0.1824,  0.2972,  0.1993],\n",
      "          [ 0.0101,  0.1182,  0.0912],\n",
      "          [ 0.0101,  0.0540,  0.0371]],\n",
      "\n",
      "         [[-0.1317, -0.2330, -0.3749],\n",
      "          [ 0.0068, -0.1081, -0.3546],\n",
      "          [ 0.0507, -0.0034, -0.2465]],\n",
      "\n",
      "         [[ 0.2432,  0.0034,  0.1993],\n",
      "          [ 0.2465, -0.0540,  0.0912],\n",
      "          [ 0.3310,  0.0473,  0.1824]],\n",
      "\n",
      "         [[-0.2060, -0.0811, -0.2229],\n",
      "          [-0.1317,  0.1756, -0.0101],\n",
      "          [-0.2330, -0.0507, -0.1182]],\n",
      "\n",
      "         [[-0.0405, -0.1081, -0.1114],\n",
      "          [ 0.0675,  0.0473, -0.0608],\n",
      "          [ 0.1554,  0.1351,  0.0405]],\n",
      "\n",
      "         [[ 0.1385,  0.0642,  0.0338],\n",
      "          [ 0.1520, -0.0135,  0.0675],\n",
      "          [ 0.2026,  0.1722,  0.2128]],\n",
      "\n",
      "         [[ 0.1013,  0.2229,  0.2161],\n",
      "          [-0.0236,  0.1824,  0.2871],\n",
      "          [-0.1925, -0.0777,  0.0439]],\n",
      "\n",
      "         [[ 0.1621,  0.3580,  0.2567],\n",
      "          [-0.0068,  0.0878,  0.1418],\n",
      "          [-0.0068,  0.1824,  0.2195]],\n",
      "\n",
      "         [[ 0.1081,  0.0203,  0.0135],\n",
      "          [ 0.1925, -0.0473,  0.0304],\n",
      "          [ 0.2229,  0.1283,  0.0811]],\n",
      "\n",
      "         [[-0.0338, -0.2567, -0.1081],\n",
      "          [ 0.1655,  0.0979,  0.1047],\n",
      "          [ 0.1486,  0.1250,  0.0844]],\n",
      "\n",
      "         [[-0.1250, -0.2972, -0.2195],\n",
      "          [ 0.0709, -0.0844, -0.1283],\n",
      "          [ 0.0371, -0.1351, -0.1824]],\n",
      "\n",
      "         [[-0.1114, -0.1081, -0.0304],\n",
      "          [-0.1587, -0.0912,  0.0270],\n",
      "          [-0.1385, -0.1114, -0.0304]],\n",
      "\n",
      "         [[ 0.2229,  0.2702,  0.2364],\n",
      "          [ 0.1520,  0.1385,  0.0811],\n",
      "          [ 0.1047,  0.0034, -0.0675]],\n",
      "\n",
      "         [[ 0.0811,  0.0507, -0.0034],\n",
      "          [ 0.1385, -0.0034,  0.0540],\n",
      "          [ 0.1554,  0.0811,  0.0878]],\n",
      "\n",
      "         [[-0.0946, -0.0608, -0.0439],\n",
      "          [-0.1452, -0.0878, -0.0169],\n",
      "          [-0.1959, -0.1013, -0.1013]],\n",
      "\n",
      "         [[ 0.0777,  0.1148,  0.0371],\n",
      "          [ 0.0878,  0.1621,  0.0169],\n",
      "          [ 0.1452,  0.1418,  0.1182]],\n",
      "\n",
      "         [[-0.0709,  0.0135, -0.1013],\n",
      "          [-0.1993, -0.0405, -0.1689],\n",
      "          [-0.1722, -0.1385, -0.1790]],\n",
      "\n",
      "         [[ 0.1486,  0.0135,  0.1824],\n",
      "          [ 0.2398,  0.0068,  0.1857],\n",
      "          [ 0.2229,  0.0371,  0.1689]],\n",
      "\n",
      "         [[ 0.1182,  0.1891,  0.1351],\n",
      "          [ 0.0203,  0.0507,  0.0574],\n",
      "          [ 0.0371,  0.0574,  0.0912]]]], size=(1, 96, 3, 3),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.0033772671595215797, zero_point=0)\n",
      "model_fp32.clshead.bias  :  Parameter containing:\n",
      "tensor([-0.0328], requires_grad=True)\n",
      "model_fp32.clshead.scale  :  tensor(0.0829)\n",
      "model_fp32.clshead.zero_point  :  tensor(212)\n",
      "model_fp32.reghead.weight  :  tensor([[[[ 0.0165, -0.0120,  0.0185],\n",
      "          [ 0.0170, -0.0040, -0.0140],\n",
      "          [-0.0180, -0.0130, -0.0145]],\n",
      "\n",
      "         [[ 0.0140, -0.0340,  0.0125],\n",
      "          [-0.0210, -0.0065,  0.0135],\n",
      "          [ 0.0065,  0.0085,  0.0185]],\n",
      "\n",
      "         [[-0.0085, -0.0210, -0.0375],\n",
      "          [-0.0115, -0.0240, -0.0125],\n",
      "          [ 0.0545,  0.0205,  0.0550]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0175, -0.0070,  0.0040],\n",
      "          [ 0.0340,  0.0300,  0.0155],\n",
      "          [-0.0320, -0.0190, -0.0415]],\n",
      "\n",
      "         [[-0.0180, -0.0100, -0.0050],\n",
      "          [ 0.0120, -0.0150,  0.0165],\n",
      "          [ 0.0015,  0.0125, -0.0040]],\n",
      "\n",
      "         [[-0.0005, -0.0130, -0.0130],\n",
      "          [ 0.0135,  0.0225,  0.0035],\n",
      "          [-0.0130, -0.0105,  0.0010]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0505, -0.0135, -0.0555],\n",
      "          [ 0.0020,  0.0260, -0.0335],\n",
      "          [ 0.0090, -0.0200, -0.0020]],\n",
      "\n",
      "         [[-0.0630,  0.0260,  0.0255],\n",
      "          [-0.0145,  0.0160,  0.0270],\n",
      "          [-0.0445, -0.0175,  0.0380]],\n",
      "\n",
      "         [[-0.0075, -0.0280,  0.0175],\n",
      "          [-0.0290,  0.0115,  0.0175],\n",
      "          [ 0.0035, -0.0155, -0.0160]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0160,  0.0090,  0.0010],\n",
      "          [ 0.0125,  0.0080, -0.0280],\n",
      "          [ 0.0000, -0.0200,  0.0045]],\n",
      "\n",
      "         [[-0.0175, -0.0035,  0.0245],\n",
      "          [ 0.0155, -0.0035, -0.0195],\n",
      "          [ 0.0040,  0.0150, -0.0170]],\n",
      "\n",
      "         [[-0.0255, -0.0205,  0.0245],\n",
      "          [-0.0185,  0.0225,  0.0260],\n",
      "          [-0.0360,  0.0105,  0.0015]]]], size=(2, 96, 3, 3),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.0004996534553356469, zero_point=0)\n",
      "model_fp32.reghead.bias  :  Parameter containing:\n",
      "tensor([-0.0079,  0.0233], requires_grad=True)\n",
      "model_fp32.reghead.scale  :  tensor(0.0063)\n",
      "model_fp32.reghead.zero_point  :  tensor(128)\n"
     ]
    }
   ],
   "source": [
    "# Export reference parameters:\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "original_stdout = sys.stdout\n",
    "\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "with open('Detection_Header_model_weights/ref_parameters.txt', 'w') as f:\n",
    "    sys.stdout = f\n",
    "\n",
    "    for keys in DH_m_int8.state_dict().keys():\n",
    "        print(keys, \" : \", DH_m_int8.state_dict()[keys])\n",
    "    sys.stdout = original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export weights (float, int8, shape), biases and other parameters from fused model:\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "original_stdout = sys.stdout\n",
    "\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "with open('Detection_Header_model_weights/parameters_float_quantized.txt', 'w') as f:\n",
    "    sys.stdout = f\n",
    "\n",
    "    for keys in DH_m_int8.state_dict().keys():\n",
    "        if('weight' in keys):\n",
    "            weights_tran =DH_m_int8.state_dict()[keys].transpose(0,1)\n",
    "            # print(keys, \"_float : \", weights_tran)\n",
    "            print(keys, \"_int8 : \", weights_tran.int_repr())\n",
    "            print(keys, \"_shape: \", weights_tran.shape)\n",
    "        elif('bias' in keys):\n",
    "            name = keys[0:-4] # take the whole name up to bias\n",
    "            bias_matrix = DH_m_int8.state_dict()[keys]\n",
    "            scale = DH_m_int8.state_dict()[name+'scale']\n",
    "            zero_point = DH_m_int8.state_dict()[name+'zero_point']\n",
    "            # print(\"!!! scale: \", scale, \" zero_point: \", zero_point)\n",
    "\n",
    "            bias_matrix = torch.div(bias_matrix, scale, rounding_mode='trunc')\n",
    "            bias_matrix = torch.add(bias_matrix, zero_point).to(torch.int8)\n",
    "\n",
    "            print(\"bias_matrix: \", bias_matrix)\n",
    "        else:\n",
    "            print(keys, \" : \", DH_m_int8.state_dict()[keys])\n",
    "            \n",
    "    sys.stdout = original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export only quantized weights from fused model:\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "original_stdout = sys.stdout\n",
    "\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "with open('Detection_Header_model_weights/weights_only.h', 'w') as f:\n",
    "    sys.stdout = f\n",
    "\n",
    "    for keys in DH_m_int8.state_dict().keys():\n",
    "        if('weight' in keys):\n",
    "            weights_tran =DH_m_int8.state_dict()[keys].transpose(0,1)\n",
    "            print(keys, \"_int8 : \", weights_tran.int_repr())\n",
    "    sys.stdout = original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([144, 256, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(DH_m_int8.model_fp32.conv1.weight().int_repr().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for save and load a model:\n",
    "def save_torchscript_model(model, model_dir, model_filename):\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model_filepath = os.path.join(model_dir, model_filename)\n",
    "    torch.jit.save(torch.jit.script(model), model_filepath)\n",
    "\n",
    "def load_torchscript_model(model_filepath, device):\n",
    "\n",
    "    model = torch.jit.load(model_filepath, map_location=device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save quantized model:\n",
    "save_torchscript_model(model=DH_m_int8, model_dir=\"/scratch2/xm0523/RADIal/RADIal/pytorch_model_quantization\", model_filename=\"Detection_Header_quant_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And save state_dict:\n",
    "torch.save(DH_m_int8.state_dict, \"/scratch2/xm0523/RADIal/RADIal/pytorch_model_quantization/DH_model_dict.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load quantized model:\n",
    "DH_quant_model = load_torchscript_model(model_filepath=\"/scratch2/xm0523/RADIal/RADIal/pytorch_model_quantization/Detection_Header_quant_model\", device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the state_dict of quantized\n",
    "DH_model_dict = torch.load(\"/scratch2/xm0523/RADIal/RADIal/pytorch_model_quantization/DH_model_dict.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(\n",
      "  original_name=Quantized\n",
      "  (quant): RecursiveScriptModule(original_name=Quantize)\n",
      "  (model_fp32): RecursiveScriptModule(\n",
      "    original_name=Detection_Header\n",
      "    (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "    (bn1): RecursiveScriptModule(original_name=Identity)\n",
      "    (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "    (bn2): RecursiveScriptModule(original_name=Identity)\n",
      "    (conv3): RecursiveScriptModule(original_name=Conv2d)\n",
      "    (bn3): RecursiveScriptModule(original_name=Identity)\n",
      "    (conv4): RecursiveScriptModule(original_name=Conv2d)\n",
      "    (bn4): RecursiveScriptModule(original_name=Identity)\n",
      "    (clshead): RecursiveScriptModule(original_name=Conv2d)\n",
      "    (reghead): RecursiveScriptModule(original_name=Conv2d)\n",
      "  )\n",
      "  (dequant): RecursiveScriptModule(original_name=DeQuantize)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(DH_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62b7252edc99e8a752c0eb79a374f0d8304b2ce60bac5a05ec44e171c445dbaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
